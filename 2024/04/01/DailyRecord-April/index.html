<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0,viewport-fit=cover"><title>DailyRecord-April | Yukino256のBlog</title><meta name="author" content="Yukino256"><meta name="copyright" content="Yukino256"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta name="description" content="4.1上午，把qwenllm&#x2F;qwen的docker image放到服务器上了，但是下午发现模型没放，还要下载72b-chat的模型再放上去；而且这个东西好像要自己写应该服务端py文件？下午复习了以下long-context的论文，看了retrieval的一些如longllama，温故知新，没跳出已有框架的同时，感觉理解更深了晚上，和SH打了一把游戏，然后和沈老师开周会，汇报了一下自己目">
<meta property="og:type" content="article">
<meta property="og:title" content="DailyRecord-April">
<meta property="og:url" content="https://yukino256.github.io/2024/04/01/DailyRecord-April/index.html">
<meta property="og:site_name" content="Yukino256のBlog">
<meta property="og:description" content="4.1上午，把qwenllm&#x2F;qwen的docker image放到服务器上了，但是下午发现模型没放，还要下载72b-chat的模型再放上去；而且这个东西好像要自己写应该服务端py文件？下午复习了以下long-context的论文，看了retrieval的一些如longllama，温故知新，没跳出已有框架的同时，感觉理解更深了晚上，和SH打了一把游戏，然后和沈老师开周会，汇报了一下自己目">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://yukino256.github.io/img/Hakuryuu.jpg">
<meta property="article:published_time" content="2024-04-01T08:10:59.000Z">
<meta property="article:modified_time" content="2024-04-26T02:00:48.251Z">
<meta property="article:author" content="Yukino256">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://yukino256.github.io/img/Hakuryuu.jpg"><link rel="shortcut icon" href="/img/favicon.png"><link rel="canonical" href="https://yukino256.github.io/2024/04/01/DailyRecord-April/index.html"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css" media="print" onload="this.media='all'"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox/fancybox.min.css" media="print" onload="this.media='all'"><script>const GLOBAL_CONFIG = { 
  root: '/',
  algolia: undefined,
  localSearch: undefined,
  translate: undefined,
  noticeOutdate: undefined,
  highlight: {"plugin":"highlighjs","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":false},
  copy: {
    success: '复制成功',
    error: '复制错误',
    noSupport: '浏览器不支持'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '',
  dateSuffix: {
    just: '刚刚',
    min: '分钟前',
    hour: '小时前',
    day: '天前',
    month: '个月前'
  },
  copyright: undefined,
  lightbox: 'fancybox',
  Snackbar: undefined,
  source: {
    justifiedGallery: {
      js: 'https://cdn.jsdelivr.net/npm/flickr-justified-gallery/dist/fjGallery.min.js',
      css: 'https://cdn.jsdelivr.net/npm/flickr-justified-gallery/dist/fjGallery.min.css'
    }
  },
  isPhotoFigcaption: false,
  islazyload: false,
  isAnchor: false,
  percent: {
    toc: true,
    rightside: false,
  }
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: 'DailyRecord-April',
  isPost: true,
  isHome: false,
  isHighlightShrink: false,
  isToc: true,
  postUpdate: '2024-04-26 10:00:48'
}</script><noscript><style type="text/css">
  #nav {
    opacity: 1
  }
  .justified-gallery img {
    opacity: 1
  }

  #recent-posts time,
  #post-meta time {
    display: inline !important
  }
</style></noscript><script>(win=>{
    win.saveToLocal = {
      set: function setWithExpiry(key, value, ttl) {
        if (ttl === 0) return
        const now = new Date()
        const expiryDay = ttl * 86400000
        const item = {
          value: value,
          expiry: now.getTime() + expiryDay,
        }
        localStorage.setItem(key, JSON.stringify(item))
      },

      get: function getWithExpiry(key) {
        const itemStr = localStorage.getItem(key)

        if (!itemStr) {
          return undefined
        }
        const item = JSON.parse(itemStr)
        const now = new Date()

        if (now.getTime() > item.expiry) {
          localStorage.removeItem(key)
          return undefined
        }
        return item.value
      }
    }
  
    win.getScript = url => new Promise((resolve, reject) => {
      const script = document.createElement('script')
      script.src = url
      script.async = true
      script.onerror = reject
      script.onload = script.onreadystatechange = function() {
        const loadState = this.readyState
        if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
        script.onload = script.onreadystatechange = null
        resolve()
      }
      document.head.appendChild(script)
    })
  
    win.getCSS = (url,id = false) => new Promise((resolve, reject) => {
      const link = document.createElement('link')
      link.rel = 'stylesheet'
      link.href = url
      if (id) link.id = id
      link.onerror = reject
      link.onload = link.onreadystatechange = function() {
        const loadState = this.readyState
        if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
        link.onload = link.onreadystatechange = null
        resolve()
      }
      document.head.appendChild(link)
    })
  
      win.activateDarkMode = function () {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      win.activateLightMode = function () {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
        }
      }
      const t = saveToLocal.get('theme')
    
          if (t === 'dark') activateDarkMode()
          else if (t === 'light') activateLightMode()
        
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        if (asideStatus === 'hide') {
          document.documentElement.classList.add('hide-aside')
        } else {
          document.documentElement.classList.remove('hide-aside')
        }
      }
    
    const detectApple = () => {
      if(/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)){
        document.documentElement.classList.add('apple')
      }
    }
    detectApple()
    })(window)</script><meta name="generator" content="Hexo 6.3.0"></head><body><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img is-center"><img src="/img/yukino.png" onerror="onerror=null;src='/img/friend_404.gif'" alt="avatar"/></div><div class="sidebar-site-data site-data is-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">8</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">10</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">7</div></a></div><hr/><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> Home</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> Archives</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> Tags</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> Categories</span></a></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-link"></i><span> Link</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> About</span></a></div></div></div></div><div class="post" id="body-wrap"><header class="post-bg" id="page-header" style="background-image: url('/img/Hakuryuu.jpg')"><nav id="nav"><span id="blog-info"><a href="/" title="Yukino256のBlog"><span class="site-name">Yukino256のBlog</span></a></span><div id="menus"><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> Home</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> Archives</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> Tags</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> Categories</span></a></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-link"></i><span> Link</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> About</span></a></div></div><div id="toggle-menu"><a class="site-page" href="javascript:void(0);"><i class="fas fa-bars fa-fw"></i></a></div></div></nav><div id="post-info"><h1 class="post-title">DailyRecord-April</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">发表于</span><time class="post-meta-date-created" datetime="2024-04-01T08:10:59.000Z" title="发表于 2024-04-01 16:10:59">2024-04-01</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">更新于</span><time class="post-meta-date-updated" datetime="2024-04-26T02:00:48.251Z" title="更新于 2024-04-26 10:00:48">2024-04-26</time></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-pv-cv" id="" data-flag-title="DailyRecord-April"><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">阅读量:</span><span id="busuanzi_value_page_pv"><i class="fa-solid fa-spinner fa-spin"></i></span></span></div></div></div></header><main class="layout" id="content-inner"><div id="post"><article class="post-content" id="article-container"><h1 id="4-1"><a href="#4-1" class="headerlink" title="4.1"></a>4.1</h1><p><strong>上午，把qwenllm&#x2F;qwen的docker image放到服务器上了，但是下午发现模型没放，还要下载72b-chat的模型再放上去；而且这个东西好像要自己写应该服务端py文件？</strong><br><strong>下午复习了以下long-context的论文，看了retrieval的一些如longllama，温故知新，没跳出已有框架的同时，感觉理解更深了</strong><br><strong>晚上，和SH打了一把游戏，然后和沈老师开周会，汇报了一下自己目前的一些理解。得到下一步的研究内容是：把retrieval 的方式在大模型上都实现一下</strong><br><strong>之后，继续和SH、NJ一起打了大乱斗</strong>  </p>
<h2 id="虽然是愚人节，但是无事发生"><a href="#虽然是愚人节，但是无事发生" class="headerlink" title=" 虽然是愚人节，但是无事发生 "></a><font color="red"> <strong>虽然是愚人节，但是无事发生</strong> </font></h2><blockquote>
<ul>
<li><strong>明日任务：阅读论文；学习修改大模型的方法</strong></li>
</ul>
</blockquote>
<h1 id="4-2"><a href="#4-2" class="headerlink" title="4.2"></a>4.2</h1><h2 id="草！这一天干啥了我给忘了！原来日记漏了一天，4-8才发现！"><a href="#草！这一天干啥了我给忘了！原来日记漏了一天，4-8才发现！" class="headerlink" title=" 草！这一天干啥了我给忘了！原来日记漏了一天，4.8才发现！ "></a><font color="red"> <strong>草！这一天干啥了我给忘了！原来日记漏了一天，4.8才发现！</strong> </font></h2><p><strong>好像还是在看代码和教程？</strong></p>
<h1 id="4-3"><a href="#4-3" class="headerlink" title="4.3"></a>4.3</h1><p><strong>上午，阅读qwen的model_qwen.py文件，尝试理解模型结构，寻找修改方法。最终目的是将kv retrieval加入到模型中去；目前没什么头绪，是直接改model文件，还是写个新的继承一下？继承的话如何与已有文件保持联系和交互？</strong><br><strong>qwen的py代码没有啥注释，突然想到可以看一下transformer包中的代码，拿llama做参考，希望有注释可以好看一点</strong><br><strong>吃了好大的饼</strong><br><strong>将4090机器上的qwen-72b-chat放到A800上，尝试让它跑起来；昨天前辈哥用vllm加速一些模型，基本上没跑起来报错，不知道是什么情况；没查到解决方案</strong></p>
<blockquote>
<ul>
<li><strong><del>明日任务：</del> 明日个P！清明节假期！</strong><br><strong><del>好吧，这个饼还是挺不错的，也许会假期学习一下。不会的好多</del></strong></li>
</ul>
</blockquote>
<h1 id="4-4-4-6"><a href="#4-4-4-6" class="headerlink" title="4.4-4.6"></a>4.4-4.6</h1><p><strong>假期第一天：上午打游戏，中午吃了昨晚下班时买的罗森便当；晚上去NJ那里，吃了川菜馆子“椒榆”（好像是这个名字），一个炒鸡、一个黄焖茄子、一个蒜泥白肉、一个小酥肉（没怎么吃，打包带回去当第二天的早饭了）；之后在附近转了转，然后坐地铁去上地一个超市逛了逛，吃了又一家杏仁豆腐，不如德和斋；打包了红豆双皮奶和一个什么奶回去第二天吃；去地铁站打道回府，路上看见北体的一个小破门，<del>另外还有漂亮MM</del>。之后到家，和SH打了会儿游戏。</strong><br><strong>假期第二天：打游戏的一天奥，无事发生！和SH、NJ打了好久的游戏；中午吃的猪脚饭，还不错；晚上吃的炸蛋螺丝混，也挺不错，熙螺湾这牌子在仙林NJU的对面也开了一家，开了不久；所以点的时候还是比较放心的。</strong><br><strong>假期第三天：中午和NJ一起去安贞门；在一家小巷子里的老馆子里面吃地地地地地地地道儿的百京菜！八大碗中的牛杂，好吃！牛肠煮的最好吃；一个炒牛尾，还行；一个羊杂砂锅，不错，但是没牛杂好吃；一个麻豆腐，挺好吃，很新奇；吃完饭，去买了芬达，合起来和大洋是有点差别，感觉大洋更好喝一点；然后沿河的公园里面有什么花展，走马观花的逛了逛。</strong><br><strong><del>忘记给NJ带德和斋杏仁豆腐了，明明前天才夸下海口…</del></strong><br><strong>三天里，没怎么学习，网络小说倒是没少看；代码什么的搞了搞但好像是在做无用功…..</strong>  </p>
<h1 id="4-7"><a href="#4-7" class="headerlink" title="4.7"></a>4.7</h1><p><strong>不想上班啊啊啊啊啊啊！</strong><br><strong>上午折腾随身wifi，顺便把qwen-72b-chat完全放到了A800的服务器上，跑了一下服务端，正常；后续工作可能就是，尝试修改模型之类的，再把后端接口什么的搞一搞？</strong><br><strong>下午，搜索阅读了一些论文，感觉收获不大；觉得是自己的代码能力不足的问题，找了篇开源代码的去读，GitHub 1k star， 但是没读懂，感觉代码写的好像不太好；遂重新阅读transformer中llama的源码；因为之前发现qwen的结构和llama很相似，希望读懂llama后能很快的触类旁通。遇到了一些问题需要记录</strong>  </p>
<blockquote>
<ul>
<li>RoPe编码的实现，看的半懂不懂，没有深究，后续视情况看是否需要深入。</li>
<li>llama attention模块中，有这两个参数，尚未搞懂作用是什么：</li>
</ul>
</blockquote>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">cache_position: <span class="type">Optional</span>[torch.LongTensor]</span><br><span class="line">position_ids: <span class="type">Optional</span>[torch.LongTensor] = <span class="literal">None</span>  </span><br></pre></td></tr></table></figure>

<p><strong>晚上在DNF神迹上抽黑钻售货机，因为没有自动抽取的功能，所以尝试用pyautogui写了个自动抽奖的脚本，但是实际运行的时候发现移动位置是对了，但无法点击到游戏程序内部的东西，又发现自己使用鼠标一直点击倒也可以，于是又开了鼠标连点器，发现鼠标连点器也点不到游戏程序内部的东西；这两种相似的现象带来的启发是：这种基于GUI模拟点击的程序，或许没有聚焦到应用程序内部，亦或者是DNF.exe的特殊性之类的。想来之前应该有一个获取游戏窗口的方法，但是不想搞了，就这样吧。</strong></p>
<blockquote>
<ul>
<li><strong>明日任务：继续阅读llama的源码</strong></li>
</ul>
</blockquote>
<h1 id="4-8"><a href="#4-8" class="headerlink" title="4.8"></a>4.8</h1><p><strong>今天，勉强把qwen的model文件看完，仍然是半懂不懂的状况，尤其是generate()和chat()这两个函数。logit的值映射到id再映射到文字，思路很好懂但代码有点复杂</strong><br><strong>后续重新看了GitHub上qwen的项目，以及modelscope上qwen7b模型的具体内容和文件。本来以为modelscope上面的是运行文件之类的，原来它真的只是模型，这个模型安装一定方式组织，transformer还是huggingface依照generation_config.json和config.json来完整的读取模型、运行之类的。运算、生成之类的函数确实是写在这个模型里面的，github上面的是介绍、示例的demo、各个数据集上的测试文件。</strong><br><strong>也就是说，如果要在模型中加入cache的retrieval，就要在modeling_qwen.py这个文件中直接修改？（但是我更希望的是，写个继承的文件然后互不影响？？）</strong><br><strong>得看看论文和论文代码去</strong><br><strong>晚上，和沈教授开了组会，表明目前的问题是不知道怎么改代码一头雾水，直接在模型文件上改感觉不稳妥；他建议我直接改试试</strong>  </p>
<blockquote>
<ul>
<li><strong>明日任务：阅读recurrent-memory-transformer，开始修改qwen代码文件</strong></li>
</ul>
</blockquote>
<h1 id="4-9"><a href="#4-9" class="headerlink" title="4.9"></a>4.9</h1><p><strong>工程师大哥入职噜！希望能带我飞！</strong><br><strong>阅读recurrent-memory-transformer的源码，思考其结构和代码作用</strong><br><strong>modeling_rmt文件，大致上应该是模型文件，其中定义了两个类，MemoryCell——似乎是负责向原有model中加入MemoryCell的类；RecurrentWrapper——似乎是可以将原有model的输出再处理之后的输出，这样看来，好像可以直接将其运用到qwen中去？</strong><br><strong>下午和GG聊了一阵子，到出租屋后又和他聊了大概一个小时；和NJ打了几把大乱斗</strong>  </p>
<blockquote>
<ul>
<li><strong>明日任务：继续阅读recurrent-memory-transformer，开始修改qwen代码文件</strong></li>
</ul>
</blockquote>
<h1 id="4-10"><a href="#4-10" class="headerlink" title="4.10"></a>4.10</h1><p>今日，新入职了一个本地学校的做数据的实习生<br><strong>上午，稍微思考了一下RMT的代码结构和用法；然后尝试在PC上跑一下千问的小模型查看效果</strong><br><strong>采用Int4版本，结果报错：</strong>  </p>
<blockquote>
<ul>
<li>CUDA extension not installed.</li>
</ul>
</blockquote>
<p>尝试安装cudatoolkit，结果依然没有解决<br>破案了，byd一直安装的cpu版本的torch之类的，可能是版本没对齐&#x2F;清华源的问题<br>来自HXD的支援：  </p>
<blockquote>
<ul>
<li>建议用pip<br>别用conda<br>conda不会检查环境里的冲突直接装<br>pip会先看有没有装</li>
</ul>
</blockquote>
<p><strong>他妈的破案了，python和torch版本太高了</strong>    </p>
<blockquote>
<ul>
<li><strong>明日任务：改千问暂停，协助跑通RAGFLOW</strong></li>
</ul>
</blockquote>
<h1 id="4-11"><a href="#4-11" class="headerlink" title="4.11"></a>4.11</h1><p>RAGFlow昨天下午工程师跑了，它最方便的功能还是直接调用api，但工程师尝试搞明白阿里的api怎么申请怎么用却失败了；从示例图上开RAgflow可以支持本地模型，但是在我们跑通的结果来看那个图上面的选项消失了，今天工程师问ragflow的群主得知，已经用ollama直接取代了。<br>似乎ollam调用更方便？准备部署ollama试试，但是由于4090显存不够了，因而要将其部署到A800上；镜像的上传又是折磨<br>踩了一个坑：  </p>
<blockquote>
<ul>
<li>scp命令指定远程端口，-p其实要大写成-P才是正确命令</li>
</ul>
</blockquote>
<p>导入之后，显示名称什么的为none，需要使用docker tag命令自己命名<br>继续琢磨怎么加mem， 想搜RMT的解析文章，结果搜出来发现说它就是Transformer-XL，然后去搜transoformer-XL，发现它是2019年的文章被拒稿了？后续改进的XLNet，这个已经被加入到了transformer官方包里面<br>查看了一些代码，感觉加不进去；但似乎渐渐得到了一些理解：这些网络结构什么的已经定好了，包括qwen，这些放在src&#x2F;model下的modeling文件定义了模型，而huggingface或者什么地方可以找到模型的一些与训练好的参数。那么已知的是qwen确实没法改模型结构？最多只能在推理的时候采取一些不影响它模型本身流动的trick，如lora&#x2F;adpter之类的东西。<br>qwen1.5采用了滑动窗口attn，可以提高推理效率；能否提高长文本能力尚不明晰。<br>似乎可行的两个思路：  </p>
<blockquote>
<ul>
<li>使用adapter，直接将之前的kv cache揉到attn里面？  </li>
<li>直接在模型推进的某一层，对kv cache和外部向量数据库 进行向量检索，然后揉进去？</li>
</ul>
</blockquote>
<p><strong>研究方向暂时转变</strong>：研究ReAct + CoT的应用；唉人在江湖身不由己，但好在是这回有人指导了，希望这段时间代码能力能有突破；越来越觉得LLM尤其需要强工程能力  </p>
<p>用千问的api，跑RAGFlow成功了，后续工作是更改成本地模型；此外，还有一些功能待添加：聊天界面可以输入图片&#x2F;文件，支持连接sql并发挥BI功能  </p>
<p>尝试用langchain，将React和CoT结合起来  </p>
<blockquote>
<ul>
<li><strong>明日任务：langchain的ReAct和CoT；了解一下CoT</strong></li>
</ul>
</blockquote>
<h1 id="4-12"><a href="#4-12" class="headerlink" title="4.12"></a>4.12</h1><p>今天没什么印象深刻的任务，在读一篇新的论文BPO，阅读它的代码。由于工程能力不足，阅读代码总是吃力半懂不懂；或许，LLM学习困难的原因在于实验条件高，我平时真的很难上手去改一些东西并快速查看效果。  </p>
<p>晚上，与ZYR和SL一起吃了聚宝源（西直门店）的涮肉；说实话感觉一般，那个B麻酱根本不香！感觉不如一般的火锅涮肉，亦或者之前在西安吃过的冰煮羊  </p>
<p>吃完饭，一起去紫什么公园逛了大概一小时；<br>今天与朋友们聊了一些求职、读博方面的事情，聊了一些高中同校、学弟学妹们的一些发展；再次感叹人外有人，每次聊天总是能感受到自己的不足，希望我能赶上去！实习实现工程能力的巨大提高！！！！  </p>
<blockquote>
<ul>
<li><strong><del>明日任务：</del> 假期噜！明天和LT，NJ一起聚一下，吃筋头巴脑！</strong>  </li>
<li><strong>下周任务： 读懂BPO代码，复现</strong></li>
</ul>
</blockquote>
<h1 id="4-13-4-14"><a href="#4-13-4-14" class="headerlink" title="4.13-4.14"></a>4.13-4.14</h1><p>周六中午，和LT，NJ一起在西二旗吃了湘菜（<del>筋头巴脑无了</del>），280的套餐，大众点评好评送手撕包菜；有臭鳜鱼、擂椒皮蛋、小炒肉、辣炒茶干、肘子肉（应该不是这个，但我想不起来具体名字了）和鸡蛋烧的一个菜；喝了可乐；<br>吃撑了，LT饭量没衰减，而我已经吃不动了，唉。<br>吃完饭，随便逛了逛；路上飞虫进眼，忙忙糟糟虚惊一场；简单粗暴地买了瓶矿泉水冲了一下眼睛。<br>和LT一起去天坛公园逛逛。路上闻到一些味道，结果发现是沙比LT的衣服馊了；想到自己当年也穿过馊的衣服而不自知，还是亲娘发现的，不免有些好笑。<br>天坛公园要购票，15一张。和LT随便逛了逛，由于他要赶火车因而走马观花，只看了很小的一部分；聊了聊过去、现在、未来。似乎朋友们没怎么变，似乎又有点变化。但朋友身边总归还是安心一点。<br>实际上，和朋友们聊天、自己写博客记录，是我迷茫的一种体现，我或许希望在交流中明心见性、获得奋斗下去的动力。  </p>
<p>下午回去，打发时间；到了10.40，SH上号叫我打LOL；周日纯躺家一天，下午1点多和SH打了两小时大乱斗。NJ撺掇我玩dota2，未果；我暂时不想花费脑子在游戏上了，新游戏的学习在上学的时候可能是快乐，但现在我没有动力。  </p>
<h1 id="4-15"><a href="#4-15" class="headerlink" title="4.15"></a>4.15</h1><p>上午又入职了一位员工。开了个会，妈的不知道现在要干啥，云里雾里的。  </p>
<p>上午看了一些东西CoT的一些东西，结果下午又告诉我回去搞长文本。这是否有点……<br>下午，被告知搞一个长文本工程思路的PPT，于是梳理了一下想法，工程思路分为三类，每个类对应目前的一个具体例子。突然发现，之前的LongMem好像可以借鉴，于是重新去看它的代码。<br>这一看不得了，之前的认识还是太浅薄了，现在感觉他的代码思路都很明晰，然后虽然用的fairseq这个我没接触过的package，但是只是为了memory的方便，因而使用它的incremental decoder类。<br>从它的eval.py、memory以及fuse等文件中，隐隐感觉到可以用在qwen上，但我需要更详细的去理解代码。这个项目中一个memory bank模块，似乎可以很方便的迁移。<br>我必须立刻发动同调！<br>沈教授今晚有事，预定的周会推迟一天噜。<br>晚上，和NJ和SH大乱斗；和SH输麻了。</p>
<blockquote>
<ul>
<li><strong>明日任务：呱！我要狠狠地使用longmem呀！</strong></li>
</ul>
</blockquote>
<h1 id="4-16"><a href="#4-16" class="headerlink" title="4.16"></a>4.16</h1><p>上午继续阅读longmem的源码；它虽说进行了解耦，但从网络结构来看，是自定义了一个层数为底模一半的网络，然后输入、训练、生成memory bank的结果，然后一直存着不动，同时底模向前运行推进，最后再加一个融合层？也许是我理解不到位，代码看错了；总之是有点搞不懂的。感觉代码好像挺不错，但转化到qwen中有难度，因为他主要用的fairseq，而我还没学过，感觉这是一个深度学习的库，自定义模型什么的。<br>下午，尝试跑一下qwen的memory增强；首先跑了基础的底模，啥都没改，让它从西游记的一段话中抽取一个信息，应该是一个大海捞针的任务，没回答出来，那我的思路就是调整模型文件来查看效果。<br>其实，下午也看了一阵子评测数据集的东西，但是也是粗略的看看没大搞懂，可能主要因为看的评测数据集与我预想中的有所区别，C-EVAL什么的是通用，但是长文本&#x2F;超长文本可能还要那种名著数据集什么的，我记得之前看过有，但是一时间忘记去找了；倒也无所谓，因为这个qwen-1.8b-chat模型本身就没有长文本能力，ntk和logn缩放都无，只有7b和14b好像支持这个；因而我采用了上面的一个测试数据。<br>修改模型还是没什么头绪，longmem究竟如何加进去？  </p>
<p>晚上，开了周例会；得到指点，预计看三篇论文、使用faiss检索并将检索结果加入prompt中作为self-RAG的baseline，需要跑通这个实验  </p>
<blockquote>
<ul>
<li><strong>明日任务：学习faiss，将输入query先切片、再faiss、再构建prompt，再输入到模型中查看效果</strong></li>
</ul>
</blockquote>
<h1 id="4-17"><a href="#4-17" class="headerlink" title="4.17"></a>4.17</h1><p>今日，尝试将query 按句子切片；结果使用nltk、langchain等切片都未果，不知什么情况；于是使用简单的split暂作切分；结果发现是这个标点符号好像有点特殊，应该是另一种编码还是什么东西？但是NLTK应该确实是不能进行中文分词的。<br>尝试了langchain的文本chunk方法，也未果，到底是怎么回事？<br>终究，实现了将query进行faiss，然后加入到prompt中去，返回的结果不是很好，可能是由于模型本身的能力不足，也有可能是prompt模板需要优化。<br>他妈的！公司的网还是没接上！我都没办法测试真正的模型的效果、没法保证自己调整的可用性。</p>
<p>晚上回家，打大乱斗；输麻了，这b游戏能不能死一死。目前寻找其他可以和朋友一起玩的游戏中……但这个更换游戏的限制其实在于朋友之间共识的达成。  </p>
<blockquote>
<ul>
<li><strong>明日任务：阅读周会上的论文，尝试优化prompt，构建模板</strong></li>
</ul>
</blockquote>
<h1 id="4-18"><a href="#4-18" class="headerlink" title="4.18"></a>4.18</h1><p>上午，稍微调整了一下prompt，之前的prompt格式有点不正确；然后测试了西游记第一章其中一节的效果，似乎有提升，但是感觉不明显，可能是因为模型不太能处理这种半古文的原因。<br>于是，切换了内部的测试数据，运行查看效果，确实提升了模型的性能。  </p>
<blockquote>
<ul>
<li><strong>思考：</strong><br><strong>首先说一下目前存在的不足</strong>：目前，对于query的faiss处理，没有实现问题与前置信息的分离，仅仅是将整个query进行cut&#x2F;chunk，然后使用faiss检索、返回topk的结果，利用其构建一个增强的query；prompt注入方法的缺点已经很明显了，这里要说的主要是未来可能的faiss&#x2F;其他向量库检索结果错误&#x2F;不匹配的问题，正如之前提到的，没有实现问题和背景的分离；此外，就算实现了分离，问题和背景知识的向量也不一定能够匹配上去。<br>目前的实践，仅仅是一个简单的test，还有许多细节需要调整：history与历史faiss向量库的保留筛选机制；faiss向量在内存中的废弃与删除；未来的应用场景应该是去理解长文本乃至超长文本，或许还要涉及生成，因而超长文本下token、input、cache等的限制也需要考虑，当然这是后面的课题。<br><strong>其次，说一下确实实现结果优化的可能原因</strong>：正如之前提到的，这种实践的方法论与理论基础比较不踏实，但为什么实现了结果优化？可能的原因在于，最后的问题，由于关键词还是语义之类的，在向量化之后确实与背景信息的某一部分高度相关，从而在query的cut与向量化之后增强了相关的向量（sentence_transformer的原理似乎在于，计算句子向量与全文向量的相关程度，从而返回topk），使得大多数情况下相关背景信息能够被 <strong>“大海捞针”</strong>，这部分topk信息，加入到prompt中去，再输入到LLM中，在LLM内部又会因为重点信息的二次&#x2F;多次出现实现attention的增强，从而增强了返回结果。</li>
</ul>
</blockquote>
<p>下午阅读TransoformerFAM的论文，但是尚未理解透彻，不太能构想出来这种结构应该怎么在代码里实现。论文中说，可以不影响之前的权重参数，也就是说应该定义一个class来作为cache？<br>内网接入许可批下来了，可以使用服务器上的模型了。</p>
<blockquote>
<ul>
<li><strong>明日任务：阅读TransformerFAM，测试服务器上的模型的prompt优化效果</strong></li>
</ul>
</blockquote>
<h1 id="4-19"><a href="#4-19" class="headerlink" title="4.19"></a>4.19</h1><p>尝试将内外网访问走的通道分离，不然每次访问内网都要断wifi就很傻逼。<br>下列命令需要cmd以管理员身份运行</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">route -p add 172.17.39.189 mask 255.255.255.0 173.17.39.254   </span><br></pre></td></tr></table></figure>
<p>三个地址分别是内网ip、内网掩码、内网网关。<del>（幸好网络接入需要mac验证，不然我这命令还不好放上来）</del>。<br>网上搜的教程还额外所有路由全走了一遍内网，纯沙比做法来的，只要这一个命令其实就可以了。  </p>
<p>突然发现自己鞋子穿的不是同一双，好笑之余，又有点感慨。或许我仍然没有长大，仍然毛毛燥燥地去面对这社会的一切，或许我就像穿上大人西装的蜡笔小新，在假装成熟。上次发生类似的事情，似乎是袜子还是什么东西穿的不是同一双，已经记不太清了。  </p>
<p>下午，整了一下午curl访问那个b服务器模型，都失败了；官方文档的命令试过了一点用也没有；但是，使用langchain的命令却成功了？？？？？基本上两小时浪费了，我真是无语子。但好消息是，这个prompt优化的效果，在7b上也很明显。<br>下午还看了一会儿TransformerFAM，似乎有一点实现的思路；不知周末是否会开始写一下 <del>（基本不可能）</del><br>今天发了一部分工资，上个月20号到本月10号的。</p>
<blockquote>
<ul>
<li><strong><del>明日任务：</del>  哇袄！高一下至高二末尾的112寝室！三分之二的四人再聚首！吃一口地地地地道儿的百京八大碗！没毛病奥老铁们！</strong>  </li>
<li><strong>下周任务：后续复现捏~</strong></li>
</ul>
</blockquote>
<h1 id="4-20-4-21"><a href="#4-20-4-21" class="headerlink" title="4.20-4.21"></a>4.20-4.21</h1><p>周六，和SL、NJ一起吃之前和NJ在安贞门吃过的那个小馆子，地道儿！点了麻豆腐、炸蘑菇、八大碗之牛杂、豆泡（这个b豆泡和麻辣烫那个味道一样，真是血亏！）、扒肉条、羊肉烧卖、蘑菇和莴苣炒的一个素菜。吃的挺好。<br>啥比LT用他之前在群里吹的向老板请假的理由来应付我们😅，家人们真是一整个无语住了。<br>啥比SL坐地铁坐反了😅，坐到他妈的朝阳门去了，多等了半小时才吃饭，百京✌坐车主打一个随心所欲说是。<br>快下地铁的时候，NJ告诉我附近有cosplay的什么展子，因为他在地铁口看见了好几个穿的奇奇怪怪的人🤣；我出地铁口的时候，看见了一个JK的背影，是那种日式JK，因为那衣服的质感啥的一看就是cosplay的。吃完饭，NJ猜测cosplay的场地是在北投购物公园，于是我们走过去看看热闹。<br>在那个购物广场里面逛了第一次，我没看见，宝可梦道馆也被查封了，但在找宝可梦道馆的路上看见了一群coser，看背影认识一个钉琦野蔷薇；出了商场到附近的地方又稍微转了转，没什么好看的；于是原路返回，想去河边的公园邹洲、看一看花，结果这时候在购物广场里面看见了一大批coser，居然有<strong>小鸟游六花</strong>，泪目，细想已经12年了；SL说看见了约尔太太；当然还看见了二字游戏的萤妹（wc！O！）；其他零零散散的coser记不清了。<br>出了购物广场，又看见两个coser进广场，看来是真有展子；其中一个是miku（我去！初音未来！），可惜听NJ说是个坦克；我看的这些coser都没看见正脸，全是背影。在b站会员购上查了查，发现真是个展子，门票80的coser展，纯cosplay交流之类的，无同人志啥的，感觉没意思，也没有啥声优给我看（**<del>樋口円香你带我走吧😭</del>*<em>），就不去看了；去河边公园逛了逛，歇了歇，帮SL看一下他碧蓝航线的装备和配队；差不多14点的时候，各自打到回府了。<br>下午，NJ发了淘宝链接给我，是大窑打折，3</em>450ml只要8.9r，于是速速下单；又问他还有无推荐，给我推荐了7月临期的盐汽水，买了；<br>到出租屋之后，躺、看小说、刷视频、打劣质游戏。<br>晚上10点多，查公主链接EX5的作业，查到一个好像能抄，遂决心战斗；耗费2k母猪石、8E玛娜，一个多小时、SL十几次，终于通关EX5；  </p>
<p>周日，混；中午吃的烤肉饭外卖，晚上吃的螺 吸 混；和SH打大乱斗；<br><strong>他妈的！返回百京的票没抢到！全是候补！五一节回不了家什么的那种事情不要啊啊啊啊啊啊啊啊啊啊啊啊！如果没办法，只能请一两天的假延迟回百京了</strong><br>晚上8、9点的时候感觉眼睛有点不舒服，干涩，又有点困，于是早早睡了；</p>
<h1 id="4-22"><a href="#4-22" class="headerlink" title="4.22"></a>4.22</h1><p>周末的时候，华为的移动wifi到了，加上之前网管过来接网线但啥事儿都没解决反而把服务器的外网权限给断了😅（<del>百京的国企✌就是爷！</del>），因而服务器和PC都会通过这个wifi相连（终于不用我开热点了！）。<br>上午，阅读Infini-Attention的论文，稍微看了一下源码。这个示例代码是基于qwen2MoE模型的，迁移到qwen-chat上应该比较容易。但是话又说回来，MoE模型与chat模型的区别在哪里，还需要阅读一下源码。<br>可能的好消息是，Inifini-attention本体的代码还挺短的。<br><del>在阅读论文中的一个疑问就是：论文中Memory cache的更新，似乎是增量循环，同时在这个过程中memory没有Norm，这样会不会数值溢出？</del> 错误的，没疑问了，activation和norm发生在后面retrieval attention的计算与检索上面。  </p>
<p>下午，比较infini和qwen2-moe原生attention之间的不同；代码和思路应该是简单的，就是把额外的memory加到attn_output里面去；<del>但是 <font color="red"><strong>为 啥 qwen2-moe 的 attention 不 做 softmax 和 norm ？</strong></font></del> 铸币了，不是在这儿加add和norm的；<br>qwen这个attention，在计算完attention之后，又对它额外做了个nn.linear。<strong>这个操作的出处是哪儿？我查了llama的源码，发现它也是这么做的</strong>————哦tmd，<strong>又铸币了</strong>，原来这是MHA，多头concat到一起之后再用linear层融合一下。理论到实践之间的距离还需要去努力弥补！<br>看代码的时候突然想到，论文中做了cache消耗的对比，infini只用额外的1.5M，而memorizing transformer用了183M，为啥会差这么多？只在某一层加入cache有那么大的消耗吗？<br>看完了项目里面的model文件，对照qwen原文件之后，确定了要改的地方，基本上就是有M_Z这个参数的地方；其他的三个文件还没看。<br>晚上，和沈教授那边开了周例会，再次明确接下来的任务是无误的。<br>和SH大乱斗，输赢参半吧，就是遇到沙比选C但是C不起来挺无语的。<br>晚上，和ZZK聊了一会儿工作的事情，他现在在上海的滴滴实习，和我吐槽房子不好、天天加班、节假日也加班、实习工资低、孤独、精气神耗尽假期也不想动……我感同身受，还是那句话，大家对上班的感受都是一样的；<del>再次感受到人的天性就是厌恶工作的。</del>上完这个B班，回家往出租屋一躺，就感觉这辈子完辣😅。<br>其实，写博客、在博客中放飞自我（指瞎几把说、粗俗用语），是我在迷茫、孤独时的一种排解手段吧；给自己找一个能看见进度的、做起来不太麻烦、有点儿动力做的事情做，可以从中感到一点活着的意义。记录日常，一方面是看看自己是不是真的有进步？另一方面，也是记录一些难以复刻的经历与心境，避免自己遗忘一些东西，像是异地的格格不入、大城市的自卑之类的。  </p>
<blockquote>
<ul>
<li><strong>明日任务：看另外三个文件，尝试修改本地的模型</strong></li>
</ul>
</blockquote>
<h1 id="4-23"><a href="#4-23" class="headerlink" title="4.23"></a>4.23</h1><p>突然发现infini-attention的项目不是官方的，而是个人自己写的；github上还有几个实现的项目。好奇怪捏，为什么那篇TransformerFAM没有人写代码？<br>对照着项目，尝试修改qwen的model文件，结果发现，示例的实现代码是基于qwen1.5的，这个代码更加简洁，相比之下qwen的model更加杂乱&#x2F;冗余？我也不知道怎么说，因为还没有看到qwen1.5的其他model源码。<br>但是反过来说，修改qwen的model尽管可能更加困难，但相比之下应该更能提升我的工程能力、加深我对大模型流程和代码的理解，还是不能畏难放弃！  </p>
<p>下午，尝试修改qwen的model文件，对照infini attention、qwen源文件、qwen1.5源文件修改；qwen1在确定在哪儿融合memory上面有难度，按理说应该在实施了RoPE且加入到cache的q、k、v这一步操作之后，再利用这个cache进行memory融合，但这个代码有点杂乱，class里面为了实现attention又写了几个method，然而在qwen1.5里面就纯没有额外方法一步到位了，实现的很清爽，在1里面有些杂乱；<br>总之，废了不少力气定位了memory加入的位置后，却又发现了另一个问题：infini里面使用的是GQA，这个所需要的参数，在1.5里面通过config可以定义、是存在的。但是在1里面，config.json文件里面并没有这个参数的影子；也就是说，qwen1是不支持GQA的。这个参数是：</p>
<blockquote>
<ul>
<li>num_key_value_heads</li>
</ul>
</blockquote>
<p>在1.5里面，GQA中，需要计算group的数值，这个数值是这么计算出来的：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">self.num_key_value_groups = self.num_heads // self.num_key_value_heads</span><br></pre></td></tr></table></figure>
<p>目前有两种思路，一是不要GQA，另一种是自己加上这个参数。在查看qwen1.5的configuration_qwen2.py之后，发现了这个新增参数它有一个默认初始化的值，初始化代码如下：  </p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> num_key_value_heads <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">    num_key_value_heads = num_attention_heads</span><br></pre></td></tr></table></figure>
<p>也就是说，如果num_key_value_heads没有定义，就默认等于num_attention_heads。我们可以直接qwen1的代码里面让它相等；这种方法实际上和不要GQA没什么区别，就是把infini的代码抄过来比较方便罢了。<br>原以为难关已经被攻破了，但在repeat_kv的时候又发现了问题：首先，qwen1里面是没这个玩意儿的，也就是说1也不支持需要repeat_kv的一系列操作；这是小事，只要去1.5里面把这个函数抄过来就行了；但关键的是1里面好像也没有对v进行cache，仅仅cache了q和k，有query_list和key_list，至少我初步看来是这样的；我得再仔细看看，真要没cache_v的话，改的工程量就太大了；还是直接去改1.5的好。<br>似乎，如果参数use_cache&#x3D;True的情况下，q、k、v是都会缓存的？而且直接就用query、key、value就行了？<br>另：infini的代码更新了，之前一些M_Z的改动似乎是不必要的，他将其删除了（这沙比owener代码有个mistake，我issue告诉他，结果他回复说“没<del>问</del>题~~”，然后立刻进行一个issue的关，结果我再看代码发现他偷偷把那个mistake给改了😅，真沙比）。<br>改好了代码，想要在本机上测试效果；结果cuda out of memory，难蚌；目前两个办法：一是换成0.5b-int4再试试，二是在服务器上部署跑一下；考虑到后续方便的问题，还是用服务器吧；但是conda create的时候报错了；解决ing……<br><strong>他妈的破案了！服务器的内存和硬盘都爆掉了！下班时间到了明日再战！</strong>  </p>
<blockquote>
<ul>
<li><strong>明日任务：在服务器上测试修改后的模型效果</strong></li>
</ul>
</blockquote>
<p>晚上，在出租屋混时间，没有打LOL；而是又拾起了✌最爱的怀旧页游！（如果WQ看到，又要搁那儿骂我山猪吃不了细糠啦！哈哈！）这游戏时不时就想捡起来玩一阵子，然后突然感觉无味、因而果断抛弃，往往下定决心再也不碰，却又偶尔想起、心痒难耐。我承认我是一个很怀旧的人，我或许一直无法脱离过去的光影。  </p>
<h1 id="4-24"><a href="#4-24" class="headerlink" title="4.24"></a>4.24</h1><p>上午，按照计划、尝试在服务器上测试修改后的模型的效果；在部署环境的间歇之余，看了一下qwen1.5的model文件，开头跃入眼帘的就是rotray embedding这个class；其实，看过的model文件，大多都像这样将其放在文件的开头；而且，基本上都是一样的写法，似乎都是从llama或者什么原初模型中copy过来的；鉴于之前并没有太搞懂其原理、代码，只是了解了五六分，因而又打算再看看；花了一阵子时间，看的眼花缭乱，最终收获却不如想象之中那么大，还是没有明晰。<br>终于，在环境部署好之后，尝试运行cli_demo.py，<strong>运行成功了！问答也能正确输出！</strong> 虽然结果不是很好，但是考虑到模型本身、以及加入的attention还没有经过ft或者什么操作，因而已经很满意了！希望这个现象代表的是：修改的内容是成功的，后续是可以推进的。  </p>
<p><strong>接下来要考虑的，主要有两方面</strong>：</p>
<blockquote>
<ul>
<li><strong>input query过长时的segment和retrieval、或许还有chat history的相关操作</strong>；  </li>
<li>infini的深入理解，与微调可能；  </li>
<li>在上述做完之后，qwen1.5的修改与尝试应该就是水到渠成的事情了</li>
</ul>
</blockquote>
<p>今天中午，又发了一部分工资，上个月20号到本月20号的。  </p>
<p>下午，看了一下其他的论文。准备看streaming-llm的代码，但是这个代码结构我得梳理一下。<br>因为苹果吃完了，所以在楼下lawson买了两个饭团当晚饭；饭团还在打折，好耶！<br>到出租屋，依然混时间；和SH打了两三个消失的大乱斗。  </p>
<blockquote>
<ul>
<li><strong>明日任务：阅读streaming-llm源码，看LLM教程。</strong></li>
</ul>
</blockquote>
<h1 id="4-25"><a href="#4-25" class="headerlink" title="4.25"></a>4.25</h1><p>今天上午，又入职了一位姑娘，似乎是北大的，和上周入职的老哥认识；捏妈，百京真是卧虎藏龙。感觉自己被Top2包围了。<br>看streaming-llm的kv-cache部分的代码，结合论文看，还是有点难懂捏。  &#x3D;&#x3D;<br>中午，突然想起来昨天改的qwen-infini代码似乎有问题；去查看之后果然如此；这么想来，昨天的cuda out of memory应该是一个失误，而不是修改模型成功运行的信号。于是，下午继续琢磨修改；遇到了许多问题。下面列出最严重的问题：</p>
<blockquote>
<ul>
<li><strong>在infini-attention的初始化模块中register_buffer了M和z，同时对其进行kaiming初始化，但是后续forward的时候，却显示M和z是NoneType</strong>：如果不对M和z进行初始化，则回在计算logit的时候报错，因为logit值都为0；这边测试了一下初始化代码的写法，至少可以保证的是，init函数中的M和z是正确初始化的、正确登记的（？）<br>————<strong>原因</strong>：如果模型权重文件里面没有这个buffer，就算我初始化了，加载权重之后也会是nonetype；所以需要在使用之前再强制初始化一下。</li>
</ul>
</blockquote>
<blockquote>
<ul>
<li><strong>此外，还有似乎是因为精度问题导致的错误：probability tensor contains either inf, nan or element &lt; 0</strong>：可能量化的模型都容易出现这个问题，百川有一个<a target="_blank" rel="noopener" href="https://github.com/baichuan-inc/Baichuan2/issues/291">issue</a>似乎可以解决；但是一个下午看的头昏脑胀，不想再加班的，明天再搞吧。</li>
</ul>
</blockquote>
<p>奥牛逼，工程师大哥鼠标灵敏度贼低，结果nm是LOL电一前二十？？？</p>
<blockquote>
<ul>
<li><strong>明日任务：解决问题</strong></li>
</ul>
</blockquote>
<h1 id="4-26"><a href="#4-26" class="headerlink" title="4.26"></a>4.26</h1><p>继续尝试修改错误，首先确定具体问题所在，根据报错结果，去修改代码，print报错之前的相关信息，其probs和softmax之后的结果打印如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#probs</span></span><br><span class="line">tensor([[-inf, -inf, -inf,  ..., -inf, -inf, -inf]], device=<span class="string">&#x27;cuda:0&#x27;</span>, dtype=torch.float16)</span><br><span class="line"></span><br><span class="line"><span class="comment">#prob_after_softmax：       </span></span><br><span class="line">tensor([[<span class="number">0.</span>, <span class="number">0.</span>, <span class="number">0.</span>,  ..., <span class="number">0.</span>, <span class="number">0.</span>, <span class="number">0.</span>]], device=<span class="string">&#x27;cuda:0&#x27;</span>, dtype=torch.float16)</span><br></pre></td></tr></table></figure>
<p>可以看到这个结果，可能是第一个token开始这个概率数值就出错了；正如昨日所说，应该是精度转化的过程中出现了问题。尝试Qwen下面一个issue的<a target="_blank" rel="noopener" href="https://github.com/QwenLM/Qwen/issues/276#issuecomment-1825326365">回答</a>，结果运行了很长世界，返回结果如下：<br><img src="error.png" alt="error" title="返回值"><br>一开始运行的时候显卡风扇咔咔吹，我还以为陷入死循环了呢，没想到还是给我返回了结果。这个结果大致上符合预期吧，因为照着上面修改了代码之后，直接选择概率最大的作为decode的值，但是从一开始到最末尾，概率值都为0的情况下，自然所有decode出来的token都是相同的；qwen中这个都是0解出来就是“！”，应该是这样的。<br>总的来说，这个结果是好的，<strong>说明修改代码没有问题，只是精度转化的问题。代码是可以正常跑通、一直decode到最后的</strong>；后面要做的就是进行微调之类的东西了；后续的问题，等到实战的时候再说吧！</p>
</article><div class="tag_share"><div class="post-meta__tag-list"></div><div class="post_share"><div class="social-share" data-image="/img/Hakuryuu.jpg" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/css/share.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/js/social-share.min.js" defer></script></div></div><nav class="pagination-post" id="pagination"><div class="next-post pull-full"><a href="/2024/03/20/DailyRecord-March/" title="DailyRecord-March"><img class="cover" src="/img/Hakuryuu.jpg" onerror="onerror=null;src='/img/404.jpg'" alt="cover of next post"><div class="pagination-info"><div class="label">下一篇</div><div class="next_info">DailyRecord-March</div></div></a></div></nav></div><div class="aside-content" id="aside-content"><div class="card-widget card-info"><div class="is-center"><div class="avatar-img"><img src="/img/yukino.png" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/></div><div class="author-info__name">Yukino256</div><div class="author-info__description">private records of CS study</div></div><div class="card-info-data site-data is-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">8</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">10</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">7</div></a></div><a id="card-info-btn" target="_blank" rel="noopener" href="https://github.com/Yukino256"><i class="fab fa-github"></i><span>Follow Me</span></a></div><div class="card-widget card-announcement"><div class="item-headline"><i class="fas fa-bullhorn fa-shake"></i><span>公告</span></div><div class="announcement_content">我永远喜欢Yukino！</div></div><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>目录</span><span class="toc-percentage"></span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#4-1"><span class="toc-number">1.</span> <span class="toc-text">4.1</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E8%99%BD%E7%84%B6%E6%98%AF%E6%84%9A%E4%BA%BA%E8%8A%82%EF%BC%8C%E4%BD%86%E6%98%AF%E6%97%A0%E4%BA%8B%E5%8F%91%E7%94%9F"><span class="toc-number">1.1.</span> <span class="toc-text"> 虽然是愚人节，但是无事发生 </span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#4-2"><span class="toc-number">2.</span> <span class="toc-text">4.2</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E8%8D%89%EF%BC%81%E8%BF%99%E4%B8%80%E5%A4%A9%E5%B9%B2%E5%95%A5%E4%BA%86%E6%88%91%E7%BB%99%E5%BF%98%E4%BA%86%EF%BC%81%E5%8E%9F%E6%9D%A5%E6%97%A5%E8%AE%B0%E6%BC%8F%E4%BA%86%E4%B8%80%E5%A4%A9%EF%BC%8C4-8%E6%89%8D%E5%8F%91%E7%8E%B0%EF%BC%81"><span class="toc-number">2.1.</span> <span class="toc-text"> 草！这一天干啥了我给忘了！原来日记漏了一天，4.8才发现！ </span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#4-3"><span class="toc-number">3.</span> <span class="toc-text">4.3</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#4-4-4-6"><span class="toc-number">4.</span> <span class="toc-text">4.4-4.6</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#4-7"><span class="toc-number">5.</span> <span class="toc-text">4.7</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#4-8"><span class="toc-number">6.</span> <span class="toc-text">4.8</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#4-9"><span class="toc-number">7.</span> <span class="toc-text">4.9</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#4-10"><span class="toc-number">8.</span> <span class="toc-text">4.10</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#4-11"><span class="toc-number">9.</span> <span class="toc-text">4.11</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#4-12"><span class="toc-number">10.</span> <span class="toc-text">4.12</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#4-13-4-14"><span class="toc-number">11.</span> <span class="toc-text">4.13-4.14</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#4-15"><span class="toc-number">12.</span> <span class="toc-text">4.15</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#4-16"><span class="toc-number">13.</span> <span class="toc-text">4.16</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#4-17"><span class="toc-number">14.</span> <span class="toc-text">4.17</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#4-18"><span class="toc-number">15.</span> <span class="toc-text">4.18</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#4-19"><span class="toc-number">16.</span> <span class="toc-text">4.19</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#4-20-4-21"><span class="toc-number">17.</span> <span class="toc-text">4.20-4.21</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#4-22"><span class="toc-number">18.</span> <span class="toc-text">4.22</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#4-23"><span class="toc-number">19.</span> <span class="toc-text">4.23</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#4-24"><span class="toc-number">20.</span> <span class="toc-text">4.24</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#4-25"><span class="toc-number">21.</span> <span class="toc-text">4.25</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#4-26"><span class="toc-number">22.</span> <span class="toc-text">4.26</span></a></li></ol></div></div><div class="card-widget card-recent-post"><div class="item-headline"><i class="fas fa-history"></i><span>最新文章</span></div><div class="aside-list"><div class="aside-list-item"><a class="thumbnail" href="/2024/04/01/DailyRecord-April/" title="DailyRecord-April"><img src="/img/Hakuryuu.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="DailyRecord-April"/></a><div class="content"><a class="title" href="/2024/04/01/DailyRecord-April/" title="DailyRecord-April">DailyRecord-April</a><time datetime="2024-04-01T08:10:59.000Z" title="发表于 2024-04-01 16:10:59">2024-04-01</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2024/03/20/DailyRecord-March/" title="DailyRecord-March"><img src="/img/Hakuryuu.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="DailyRecord-March"/></a><div class="content"><a class="title" href="/2024/03/20/DailyRecord-March/" title="DailyRecord-March">DailyRecord-March</a><time datetime="2024-03-20T12:16:21.000Z" title="发表于 2024-03-20 20:16:21">2024-03-20</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2024/03/14/%E5%AE%9E%E4%B9%A0%E5%87%86%E5%A4%87/" title="第一次实习前的一些准备工作与知识储备"><img src="/img/Hakuryuu.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="第一次实习前的一些准备工作与知识储备"/></a><div class="content"><a class="title" href="/2024/03/14/%E5%AE%9E%E4%B9%A0%E5%87%86%E5%A4%87/" title="第一次实习前的一些准备工作与知识储备">第一次实习前的一些准备工作与知识储备</a><time datetime="2024-03-14T13:52:22.000Z" title="发表于 2024-03-14 21:52:22">2024-03-14</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2023/06/15/PcrQQbot/" title="云服务器使用及QQ机器人搭建"><img src="/img/Kaga.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="云服务器使用及QQ机器人搭建"/></a><div class="content"><a class="title" href="/2023/06/15/PcrQQbot/" title="云服务器使用及QQ机器人搭建">云服务器使用及QQ机器人搭建</a><time datetime="2023-06-15T10:36:51.000Z" title="发表于 2023-06-15 18:36:51">2023-06-15</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2023/04/25/AIdrawing/" title="AI绘画初步尝试：Stable Difussion本地部署及WebUI使用"><img src="/img/Hakuryuu.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="AI绘画初步尝试：Stable Difussion本地部署及WebUI使用"/></a><div class="content"><a class="title" href="/2023/04/25/AIdrawing/" title="AI绘画初步尝试：Stable Difussion本地部署及WebUI使用">AI绘画初步尝试：Stable Difussion本地部署及WebUI使用</a><time datetime="2023-04-25T06:10:31.000Z" title="发表于 2023-04-25 14:10:31">2023-04-25</time></div></div></div></div></div></div></main><footer id="footer"><div id="footer-wrap"><div class="copyright">&copy;2020 - 2024 By Yukino256</div><div class="framework-info"><span>框架 </span><a target="_blank" rel="noopener" href="https://hexo.io">Hexo</a><span class="footer-separator">|</span><span>主题 </span><a target="_blank" rel="noopener" href="https://github.com/jerryc127/hexo-theme-butterfly">Butterfly</a></div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="阅读模式"><i class="fas fa-book-open"></i></button><button id="darkmode" type="button" title="浅色和深色模式转换"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="单栏和双栏切换"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside_config" type="button" title="设置"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="目录"><i class="fas fa-list-ul"></i></button><button id="go-up" type="button" title="回到顶部"><span class="scroll-percent"></span><i class="fas fa-arrow-up"></i></button></div></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox/fancybox.umd.min.js"></script><div class="js-pjax"></div><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script></div></body></html>