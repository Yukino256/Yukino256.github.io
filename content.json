{"meta":{"title":"Yukino256のBlog","subtitle":"————我永远喜欢雪之下雪乃","description":"private records of CS study","author":"Yukino256","url":"https://Yukino256.github.io","root":"/"},"pages":[{"title":"搜索","date":"2023-04-20T08:12:14.000Z","updated":"2024-03-31T00:48:51.002Z","comments":true,"path":"search/index.html","permalink":"https://yukino256.github.io/search/index.html","excerpt":"","text":""},{"title":"标签","date":"2023-04-20T08:10:01.000Z","updated":"2024-03-31T00:49:02.777Z","comments":true,"path":"tags/index.html","permalink":"https://yukino256.github.io/tags/index.html","excerpt":"","text":""},{"title":"分类","date":"2023-04-20T08:08:57.000Z","updated":"2024-03-31T00:48:37.781Z","comments":true,"path":"categories/index.html","permalink":"https://yukino256.github.io/categories/index.html","excerpt":"","text":""},{"title":"友链","date":"2024-03-28T09:28:20.000Z","updated":"2024-03-31T00:48:21.701Z","comments":true,"path":"link/index.html","permalink":"https://yukino256.github.io/link/index.html","excerpt":"","text":""},{"title":"","date":"2024-03-28T09:51:20.593Z","updated":"2024-03-28T09:51:20.593Z","comments":true,"path":"css/modify.css","permalink":"https://yukino256.github.io/css/modify.css","excerpt":"","text":"#page-header { background: transparent !important; } #page-header.post-bg, #page-header.not-home-page { height: 280px !important; } #page-header #post-info { bottom: 40px !important; text-align: center; } #page-header #page-site-info { top: 140px !important; } @media screen and (max-width: 768px) { #page-header.not-home-page { height: 200px !important; } #page-header #post-info { bottom: 10px !important; } #page-header #page-site-info { top: 100px !important; } } .top-img { height: 250px; margin: -50px -40px 50px; border-top-left-radius: inherit; border-top-right-radius: inherit; background-position: center center; background-size: cover; -webkit-transition: all 0.3s; -moz-transition: all 0.3s; -o-transition: all 0.3s; -ms-transition: all 0.3s; transition: all 0.3s; } @media screen and (max-width: 768px) { .top-img { height: 230px; margin: -36px -14px 36px; } } [data-theme='dark'] .top-img { filter: brightness(0.8); } #footer:before { background-color: rgba(255,255,255,0.5); } [data-theme='dark'] #footer:before { background-color: rgba(0,0,0,0.5); } #footer-wrap, #footer-wrap a { color: #111; -webkit-transition: unset; -moz-transition: unset; -o-transition: unset; -ms-transition: unset; transition: unset; } [data-theme='dark'] #footer-wrap, [data-theme='dark'] #footer-wrap a { color: var(--light-grey); }"}],"posts":[{"title":"DailyRecord-April","slug":"DailyRecord-April","date":"2024-04-01T08:10:59.000Z","updated":"2024-04-15T02:27:19.930Z","comments":true,"path":"2024/04/01/DailyRecord-April/","link":"","permalink":"https://yukino256.github.io/2024/04/01/DailyRecord-April/","excerpt":"","text":"4.1上午，把qwenllm&#x2F;qwen的docker image放到服务器上了，但是下午发现模型没放，还要下载72b-chat的模型再放上去；而且这个东西好像要自己写应该服务端py文件？下午复习了以下long-context的论文，看了retrieval的一些如longllama，温故知新，没跳出已有框架的同时，感觉理解更深了晚上，和SH打了一把游戏，然后和沈老师开周会，汇报了一下自己目前的一些理解。得到下一步的研究内容是：把retrieval 的方式在大模型上都实现一下之后，继续和SH、NJ一起打了大乱斗 虽然是愚人节，但是无事发生 明日任务：阅读论文；学习修改大模型的方法 4.2 草！这一天干啥了我给忘了！原来日记漏了一天，4.8才发现！ 好像还是在看代码和教程？ 4.3上午，阅读qwen的model_qwen.py文件，尝试理解模型结构，寻找修改方法。最终目的是将kv retrieval加入到模型中去；目前没什么头绪，是直接改model文件，还是写个新的继承一下？继承的话如何与已有文件保持联系和交互？qwen的py代码没有啥注释，突然想到可以看一下transformer包中的代码，拿llama做参考，希望有注释可以好看一点吃了好大的饼将4090机器上的qwen-72b-chat放到A800上，尝试让它跑起来；昨天前辈哥用vllm加速一些模型，基本上没跑起来报错，不知道是什么情况；没查到解决方案 明日任务： 明日个P！清明节假期！好吧，这个饼还是挺不错的，也许会假期学习一下。不会的好多 4.4-4.6假期第一天：上午打游戏，中午吃了昨晚下班时买的罗森便当；晚上去NJ那里，吃了川菜馆子“椒榆”（好像是这个名字），一个炒鸡、一个黄焖茄子、一个蒜泥白肉、一个小酥肉（没怎么吃，打包带回去当第二天的早饭了）；之后在附近转了转，然后坐地铁去上地一个超市逛了逛，吃了又一家杏仁豆腐，不如德和斋；打包了红豆双皮奶和一个什么奶回去第二天吃；去地铁站打道回府，路上看见北体的一个小破门，另外还有漂亮MM。之后到家，和SH打了会儿游戏。假期第二天：打游戏的一天奥，无事发生！和SH、NJ打了好久的游戏；中午吃的猪脚饭，还不错；晚上吃的炸蛋螺丝混，也挺不错，熙螺湾这牌子在仙林NJU的对面也开了一家，开了不久；所以点的时候还是比较放心的。假期第三天：中午和NJ一起去安贞门；在一家小巷子里的老馆子里面吃地地地地地地地道儿的百京菜！八大碗中的牛杂，好吃！牛肠煮的最好吃；一个炒牛尾，还行；一个羊杂砂锅，不错，但是没牛杂好吃；一个麻豆腐，挺好吃，很新奇；吃完饭，去买了芬达，合起来和大洋是有点差别，感觉大洋更好喝一点；然后沿河的公园里面有什么花展，走马观花的逛了逛。忘记给NJ带德和斋杏仁豆腐了，明明前天才夸下海口…三天里，没怎么学习，网络小说倒是没少看；代码什么的搞了搞但好像是在做无用功….. 4.7不想上班啊啊啊啊啊啊！上午折腾随身wifi，顺便把qwen-72b-chat完全放到了A800的服务器上，跑了一下服务端，正常；后续工作可能就是，尝试修改模型之类的，再把后端接口什么的搞一搞？下午，搜索阅读了一些论文，感觉收获不大；觉得是自己的代码能力不足的问题，找了篇开源代码的去读，GitHub 1k star， 但是没读懂，感觉代码写的好像不太好；遂重新阅读transformer中llama的源码；因为之前发现qwen的结构和llama很相似，希望读懂llama后能很快的触类旁通。遇到了一些问题需要记录 RoPe编码的实现，看的半懂不懂，没有深究，后续视情况看是否需要深入。 llama attention模块中，有这两个参数，尚未搞懂作用是什么： cache_position: Optional[torch.LongTensor] position_ids: Optional[torch.LongTensor] &#x3D; None 晚上在DNF神迹上抽黑钻售货机，因为没有自动抽取的功能，所以尝试用pyautogui写了个自动抽奖的脚本，但是实际运行的时候发现移动位置是对了，但无法点击到游戏程序内部的东西，又发现自己使用鼠标一直点击倒也可以，于是又开了鼠标连点器，发现鼠标连点器也点不到游戏程序内部的东西；这两种相似的现象带来的启发是：这种基于GUI模拟点击的程序，或许没有聚焦到应用程序内部，亦或者是DNF.exe的特殊性之类的。想来之前应该有一个获取游戏窗口的方法，但是不想搞了，就这样吧。 明日任务：继续阅读llama的源码 4.8今天，勉强把qwen的model文件看完，仍然是半懂不懂的状况，尤其是generate()和chat()这两个函数。logit的值映射到id再映射到文字，思路很好懂但代码有点复杂后续重新看了GitHub上qwen的项目，以及modelscope上qwen7b模型的具体内容和文件。本来以为modelscope上面的是运行文件之类的，原来它真的只是模型，这个模型安装一定方式组织，transformer还是huggingface依照generation_config.json和config.json来完整的读取模型、运行之类的。运算、生成之类的函数确实是写在这个模型里面的，github上面的是介绍、示例的demo、各个数据集上的测试文件。也就是说，如果要在模型中加入cache的retrieval，就要在modeling_qwen.py这个文件中直接修改？（但是我更希望的是，写个继承的文件然后互不影响？？）得看看论文和论文代码去晚上，和沈教授开了组会，表明目前的问题是不知道怎么改代码一头雾水，直接在模型文件上改感觉不稳妥；他建议我直接改试试 明日任务：阅读recurrent-memory-transformer，开始修改qwen代码文件 4.9工程师大哥入职噜！希望能带我飞！阅读recurrent-memory-transformer的源码，思考其结构和代码作用modeling_rmt文件，大致上应该是模型文件，其中定义了两个类，MemoryCell——似乎是负责向原有model中加入MemoryCell的类；RecurrentWrapper——似乎是可以将原有model的输出再处理之后的输出，这样看来，好像可以直接将其运用到qwen中去？下午和GG聊了一阵子，到出租屋后又和他聊了大概一个小时；和NJ打了几把大乱斗 明日任务：继续阅读recurrent-memory-transformer，开始修改qwen代码文件 4.10今日，新入职了一个本地学校的做数据的实习生上午，稍微思考了一下RMT的代码结构和用法；然后尝试在PC上跑一下千问的小模型查看效果采用Int4版本，结果报错： CUDA extension not installed. 尝试安装cudatoolkit，结果依然没有解决破案了，byd一直安装的cpu版本的torch之类的，可能是版本没对齐&#x2F;清华源的问题来自HXD的支援： 建议用pip别用condaconda不会检查环境里的冲突直接装pip会先看有没有装 他妈的破案了，python和torch版本太高了 明日任务：改千问暂停，协助跑通RAGFLOW 4.11RAGFlow昨天下午工程师跑了，但是它最方便的功能还是直接调用api，但工程师尝试搞明白阿里的api怎么申请怎么用却失败了；从示例图上开RAgflow可以支持本地模型，但是在我们跑通的结果来看那个图上面的选项消失了，今天工程师问ragflow的群主得知，已经用ollama直接取代了。似乎ollam调用更方便？准备部署ollama试试，但是由于4090显存不够了，因而要将其部署到A800上；镜像的上传又是折磨踩了一个坑： scp命令指定远程端口，-p其实要大写成-P才是正确命令 导入之后，显示名称什么的为none，需要使用docker tag命令自己命名继续琢磨怎么加mem， 想搜RMT的解析文章，结果搜出来发现说它就是Transformer-XL，然后去搜transoformer-XL，发现它是2019年的文章被拒稿了？后续改进的XLNet，这个已经被加入到了transformer官方包里面查看了一些代码，感觉加不进去；但似乎渐渐得到了一些理解：这些网络结构什么的已经定好了，包括qwen，这些放在src&#x2F;model下的modeling文件定义了模型，而huggingface或者什么地方可以找到模型的一些与训练好的参数。那么已知的是qwen确实没法改模型结构？最多只能在推理的时候采取一些不影响它模型本身流动的trick，如lora&#x2F;adpter之类的东西。qwen1.5采用了滑动窗口attn，可以提高推理效率；能否提高长文本能力尚不明晰。似乎可行的两个思路： 使用adapter，直接将之前的kv cache揉到attn里面？ 直接在模型推进的某一层，对kv cache和外部向量数据库 进行向量检索，然后揉进去？ 研究方向暂时转变：研究ReAct + CoT的应用；唉人在江湖身不由己，但好在是这回有人指导了，希望这段时间代码能力能有突破；越来越觉得LLM尤其需要强工程能力 用千问的api，跑RAGFlow成功了，后续工作是更改成本地模型；此外，还有一些功能待添加：聊天界面可以输入图片&#x2F;文件，支持连接sql并发挥BI功能 尝试用langchain，将React和CoT结合起来 明日任务：langchain的ReAct和CoT；了解一下CoT 4.12今天没什么印象深刻的任务，在读一篇新的论文BPO，阅读它的代码。由于工程能力不足，阅读代码总是吃力半懂不懂；或许，LLM学习困难的原因在于实验条件高，我平时真的很难上手去改一些东西并快速查看效果。 晚上，与ZYR和SL一起吃了聚宝源（西直门店）的涮肉；说实话感觉一般，那个B麻酱根本不香！感觉不如一般的火锅涮肉，亦或者之前在西安吃过的冰煮羊 吃完饭，一起去紫什么公园逛了大概一小时；今天与朋友们聊了一些求职、读博方面的事情，聊了一些高中同校、学弟学妹们的一些发展；再次感叹人外有人，每次聊天总是能感受到自己的不足，希望我能赶上去！实习实现工程能力的巨大提高！！！！ 明日任务： 假期噜！明天和LT，NJ一起聚一下，吃筋头巴脑！ 下周任务： 读懂BPO代码，复现 4.13-4.14周六中午，和LT，NJ一起在西二旗吃了湘菜，280的套餐，大众点评好评送手撕包菜；有臭鳜鱼、擂椒皮蛋、小炒肉、辣炒茶干、肘子肉（应该不是这个，但我想不起来具体名字了）和鸡蛋烧的一个菜；喝了可乐；吃撑了，凌童饭量没衰减，而我已经吃不动了，唉。吃完饭，随便逛了逛；路上飞虫进眼，忙忙糟糟虚惊一场；简单粗暴地买了瓶矿泉水冲了一下眼睛。和LT一起去天坛公园逛逛。路上闻到一些味道，结果发现是沙比LT的衣服馊了；想到自己当年也穿过馊的衣服而不自知，还是亲娘发现的，不免有些好笑。天坛公园要购票，15一张。和LT随便逛了逛，由于他要赶火车因而走马观花，只看了很小的一部分；聊了聊过去、现在、未来。似乎朋友们没怎么变，似乎又有点变化。但朋友身边总归还是安心一点。实际上，和朋友们聊天、自己写博客记录，是我迷茫的一种体现，我或许希望在交流中明心见性、获得奋斗下去的动力。 下午回去，打发时间；到了10.40，SH上号叫我打LOL；周日纯躺家一天，下午1点多和SH打了两小时大乱斗。NJ撺掇我玩dota2，未果；我暂时不想花费脑子在游戏上了，新游戏的学习在上学的时候可能是快乐，但现在我没有动力。","categories":[],"tags":[]},{"title":"DailyRecord-March","slug":"DailyRecord-March","date":"2024-03-20T12:16:21.000Z","updated":"2024-04-07T02:58:04.789Z","comments":true,"path":"2024/03/20/DailyRecord-March/","link":"","permalink":"https://yukino256.github.io/2024/03/20/DailyRecord-March/","excerpt":"","text":"3.20入职的第一天，接到的任务是：把闻达的demo在服务器上用docker给搭建出来。于是我在服务器上先创建了一个miniconda3的docker，然后使用conda安装了一些依赖、git项目等；其间遇到一个问题：docker+conda后，尽管bash上显示是root，但是好像是一个虚拟的root，没有sudo等的执行文件，需要重新安装一下。此外，公司的网有点差，清华源1Mb、不用清华源只有几十kb。因而进展较慢部署步骤进行到了模型下载这一步，但是因为网不好所以连不上hugging face，需要搭梯子。下班了，明天再搞！ 明日任务：搞定梯子，下载好生成模型和embedding模型，最终完成demo，并调整远程访问展示 3.21今天签合同了。搭梯子问题卡了好久😡。这国企是一天也不能待了，网差的要死。最后还是前辈哥帮忙解决的。但是terminal的命令，下载的那些怎么都那么几把慢啊！网速是压力之源！更悲剧的是：今日闻达demo部署至最后一步无法运行…………..可能是docker的问题，因而将其删除从头开始搭建。如果明天仍然不行，则尝试不用docker直接在服务器上部署 他妈的！狗日的北京通勤太痛苦了！ 明日任务：wenda的demo。哎我真佛了这个b服务器 + docker好难用，不能直接在服务器安装conda吗，conda创建虚拟环境不也挺方便的 3.22创建了一个git的container，但是在安装lfs的时候出了问题，需要用sudo等一些命令，但是apt下载很慢，似乎需要在docker file文件中就更换镜像源了解了docker中与宿主机相互cp文件、docker在创建时需要用GPU对容器可见的命令； docker run -it –net&#x3D;host –gpus all –name 容器名 -e NVIDIA_DRIVER_CAPABILITIES&#x3D;compute,utility -e NVIDIA_VISIBLE_DEVICES&#x3D;all 镜像名 闻达demo终于无报错安装起来了但是运行的时候，模型似乎卡住&#x2F;死循环？不返回计算结果。 他妈的！压力一天比一天大！EMO了要！ 今天美好的事情：与SL、ZYR一起在附近那啥招待所吃川菜。味道不错，就是环境有点热、菜有点辣。此外，和ZYR一起自行车骑行，他一路讲解，聊的很开心！到北京以来为数不多的快乐时间。SL骑着他那破电瓶车，本来跟我们一起的，半路给交警罚款了，就让他回去了，唉，我好难过 下周任务：调整闻达demo 3.23-3.24 周末！早上乘坐地铁到清河，和NJ汇合，一起去清河做了半小时火车到怀来辣！比北京通勤还快。下了火车有一种终于逃离压力之源的舒畅感。中文在饭店吃了什么洋葱和羊肉炒的东西，味道不错；然后还吃了莜面、炒扁豆角；喝了营养快线味的酸奶、杏仁露。杏仁露味道不错，加热和不加热是两个味道吃完饭和NJ一起顺路去菜市场买了点粑粑柑（最后一口没吃带回北京了）。然后不行一阵子去了宾馆，双人间一晚90，条件还挺不错….要哭了睡了午觉，然后出去找网吧打了几把大乱斗；下了新赛季的第一把云顶，玩不明白好痛苦，老六老七出局。然后出去转了转，看了一下县城的风土人情，买了西安特产甑糕，味道也不错。天气不好，阴沉天空使我不太开心。相对于老家，这里明显更荒凉一些，没有人、没有年轻人。晚上吃了砂锅。酸菜白肉和竹笋炖腊肉的砂锅；点了傀儡（土豆和面的混合物作为主食？），咸咸的，有葱花。点了冰糖芦荟，和椰果罐头一个味儿。吃完又转了转。回到宾馆玩了把金铲铲，然后下去买了10斤的半个西瓜和勺子。吃了一点，大头给NJ吃了（真能吃啊这B）睡了一晚，第二天早上吃了豆面还是什么东西，然后走路去买了个吊炉烧饼分着尝尝；NJ点了驴肉和驴肠火烧的外卖，带回北京吃了和NJ回北京了，BYD带我在海淀区骑了好久的自行车，最后在一家新疆馆子吃了抓饭和羊肉什么馍，喝了北京的汽水（和芬达一个味），吃的挺好。就是这b人带我转来转去最后吃这种快餐属实没绷住 3.25闻达demo部署完毕辣！接下来需要：尝试更换通义7B&#x2F;14B的模型；查看闻达前端技术栈，与前端做交接让其修改；部署另一个&#x2F;几个项目（似乎要加班，tmd！）已经将底模更新为7B，但是14B可能需要双卡，还不了解他这个框架怎么放到双卡上；前端框架不太清楚，但是有一个二次开发的前端框架正在尝试，但是服务器网不好，nodejs安装困难。下午看了B站上的一个从零开始大模型，感觉有点收获。还有一部分没看完 明日任务：或许需要看一下另一个agent代理的部署；看langchain和LLM的相关教程视频；RAG目前似乎有一套实践模板，基于faiss检索？ 3.26早上看langchain的视频教程下午部署了wenda的二次开发webui，其中有报错；能保证基本的对话，但是文档对话功能用不了下午抽空去面了腾讯的NLP应用研究实习生，他们是做腾讯视频剧本理解与智能助手的，感觉挺有意思。花了114定了钟点房，可惜面试的时候网不好、代码题（手写交叉熵、双指针&#x2F;滑动数组解决list中满足和为n的最小连续长度）也没敲出来，BERT的损失函数、交叉熵也没回答好。 和SH交流了一下面试的经历，他目前的实习产品经理似乎工资低但是很轻松。他说TX面试结果很快会出，就可以再投了，但是我到第二天也没看到结果部署了langchain-chatchat，可以基本运行，但存在一些问题，如知识库检索似乎没有工作、模型更换没有前端，需要在后端尝试修改 回家，地铁上和ZJX吐槽工作的事情，交流中得到片刻的安慰；到家后，和NJ电话聊了聊，大诉苦水，得到了一些开导和建议，好兄弟！；夜里躺在床上，和LF聊了聊他的离职和走全奖去美国读PHD躺平5年。唏嘘之余，有点羡慕 似乎，上班的人状况都不是很好：ZYR精神衰弱吃药、LF压力大怼领导辞职、SX天天emo不想动，我自己的精神状态也不是很好，唉。唉！ 明日任务：调整部署项目，学习 3.27早上给领导演示了一下两个demo，边上的前辈哥部署的DB-GPT也看了；这个效果挺好，但是也有要调整的地方。如服务器上部署模型的API调用等今天看阿里Qwen的vllm教程视频，大有收获铸币吧，LLM聊天一个字一个字显示的效果原来是清屏+ 打印啊！前端或许就是&lt;div&gt;内部的反复刷新？ 明日任务：调整部署项目，学习 晚上，和妈妈聊了聊天，倾诉了一下。得知妹妹的奶奶肿瘤晚期，突然有一种恐惧和悲伤笼罩心头。帮妈妈网上填写了检查需要的材料，相关材料也进行了保存。与SH、LMD一起打了大乱斗，片刻的开心，但是过程中没有完全放松。 3.28继续学习qwen+vllm的宝藏up主。对asyncio的内容有些不理解。这个up主好像是c++、java高手，学习大模型相关内容上手也很快，我感到很挫败。小米面试，问Qquant还是啥的量化不了解，adapter不了解，代码题一是n个全排列中k个逆序对数量，完全不会；一个是写梯度下降求算术平方根，初始化值、lr和反向传播这些都写的不太好下午，视频看的差不多了，准备看一下Dify是个什么东西晚上，打SH、NJ打游戏，和妈妈视频，开森和沈晓宇老师的师姐聊了聊城市、职业规划、未来发展，感觉认知更清晰了 明日任务：学习 悲苦萦绕心头，不能散去。可能真的是房子住的还是有点远，每天通勤1.5小时。或许我需要换租了。 3.28上午看了一会儿视频，然后捣鼓4090那台机子的docker和conda，没捣鼓出东西来。下午问了前辈，了解怎么搞了，稍微搞了一点下午，搞了会langchain-chatchat，发现推理慢的原因可能是gpu被占了；没找到如何更换模型为qwen 下周任务：qwenllm&#x2F;qwen的docker image本地下载好并上传到远程服务器上，运行查看效果 又 放 假 辣 ！ 3.30-3.31 周末！周六早上，和SH打了LOL，中午出去吃了吉野家；下午躺了一会儿，然后晚上和NJ去逛了古玩市场，感觉有点同质化。之后吃了白糖汁儿的杏仁豆腐，然后吃了永和大王的快餐，赶紧赶地铁回来参加TX的笔试题。但实际上我一面已经挂了，结果现在才出来，这题就没必要做了实际上，而且五题只做出来第一题，似乎打竞赛的才能做得出来多题，唉…又和SH打了一会儿大乱斗看小说，睡觉！","categories":[],"tags":[]},{"title":"第一次实习前的一些准备工作与知识储备","slug":"实习准备","date":"2024-03-14T13:52:22.000Z","updated":"2024-03-17T13:53:12.026Z","comments":true,"path":"2024/03/14/实习准备/","link":"","permalink":"https://yukino256.github.io/2024/03/14/%E5%AE%9E%E4%B9%A0%E5%87%86%E5%A4%87/","excerpt":"","text":"千帆杯原生应用挑战赛 大赛主旨：大赛以“创意无限·生成未来”为主题，紧密围绕当前AI技术的前沿动态和应用趋势，借助百度智能云千帆AppBuilder和ModelBuilder两大智能开发助手，鼓励参赛者打造出更多具有创新性、实用性和社会价值的AI原生应用 第一期：游乐场排队规划助手：赛题聚焦春节假期游乐园排队效率问题，鼓励开发者利用 AI 能力施展“时间魔法”，打造一款具有实用性的“游乐场排队规划助手”，帮助游客更好地了解乐园的排队情况，设计个性化的游玩路线，在有限的时间内获得最“High”的体验，同时为管理者提供优化运营策略的决策支持。 此大赛没有规定数据集，需求成果是使用主办方框架的应用程序。参赛者需要自己获取相关数据，如大赛第一名使用的是香港迪士尼数据 第二期：生成一个可制作贺岁文案内容的精调模型（限定使用ERNIE Speed，通过对模型精调使其保持原有能力的同时，具备准确理解并执行文案创作中创作长度相关指令的能力）。 此大赛提供了少量数据集（56）条，同时要求对数据集进行扩展（最终至少需要100条数据），数据为json形式 与第一期不同，此期是方向特化的微调模型开发，需要使用主办方框架 大赛形式： 第一期：基于AppBuilder平台提供的强大开发套件和资源环境，使用平台预置的Agent框架，以零代码的方式创建Agent智能体，自动化调用各种工具打造游乐场排队规划助手AI原生应用。 游客只需要输入时间预算和游玩喜好，Agent智能体就能生成并执行Python代码，求解优化问题，智能规划出游玩项目路线。————————生成python，求解optimization问题的agent 第二期：通过在千帆大模型平台使用平台上的各种模型调优工具，结合相关数据，基于ERNIE-Speed调优生成符合赛题主题要求且效果优秀的模型。 作品信息需包含： 微调后的模型效果展示（输入输出示例截图） 部署后的模型API文档（包含url地址、超参配置和步骤描述） access_token； 阿里天池竞赛1. 基于LLM智能问答系统学习赛 赛题思想：未来金融科技领域将深刻体现Agent的价值，即一个智能代理能根据用户需求进行意图识别和决策。本次大赛的赛题虽为单一，但融合了数据查询与文本理解两大任务，充分体现了Agent核心思想：根据不确定输入，判断用户意图，并调用相应服务或功能生成答案。 模型使用：不限制选手的模型使用，选手可以选择商业化模型或者开源模型，也可以结合多个模型，共同创建一个问答系统。可以采用Prompt Engineering方法，也可以使用外部数据对模型进行微调。推荐使用“通义千问金融大模型”或“通义千问7B模型”作为基础大模型， 任务目标：数据查询题——根据用户的问题，生成相应的SQL查询语句，精准查询问题结果；文本理解题：对长文本进行细致检索与解读，高效提取关键信息。 数据集描述：赛事主办方提供三类数据。一个是10张数据表（sqlite），一个是招股说明书（pdf文件，标准的招股说明书形式，没有进行数据处理），以及将招股说明书pdf解析后的txt文件。 大模型拓展操作：扩展金融行业词表；增量训练行业金融200B规模，涵盖中英文财报、研报、新闻、书籍、论坛等多种类型数据；训练上下文扩展到16K，借助NTK和LogN等技术，推理长度可以扩展到64K 2. 通义千问AI挑战赛 - Code Qwen能力算法赛道 目的：如何通过高质量的数据微调提升基础语言模型的代码能力？——聚焦于通义千问大模型微调训练的竞赛，其主要目标是通过高质量的数据探索和拓展开源模型 Qwen 1.8B 及 Qwen 72B 的代码能力上限。高质量的数据是大模型提升效果的关键，初赛阶段主要聚焦在如何通过 SFT 提升基础模型的代码能力。需要选手基于最新开源的 Qwen 1.8 模型作为基础模型，在提供的训练框架上自行进行数据收集与微调，训练完成后将进行自动评估，返回最终结果进行排名； 数据集特征 Evol-instruction-66k： 基于开源open-evol-instruction-80k过滤低质量，重复和human eval相似的数据后得到的高质量代码类微调数据 e.x.{ “instruction”: “Using the text file from the link, https://norvig.com/big.txt, use the SpellChecker module from the pyspellchecker package in Python to find spelling mistakes in the text file. Additionally, measure the efficiency of the implemented spell checker. Report the number of false positives and false negatives, and provide a way to visualize these instances. Also, improve the spell checker by using custom dictionaries or other natural language processing techniques to reduce these errors.”, “output”: “Here is an outline of how to address this problem:\\n(Note we will need to install pyspellchecker and requests dependencies if not present already). You can install it using:\\n\\npip install pyspellchecker requests\\n\\n\\npython\\nimport requests\\nfrom spellchecker import SpellChecker\\n\\n# Get the text file\\nurl = \\&quot;https://norvig.com/big.txt\\&quot;\\nresponse = requests.get(url)\\ntext = response.text\\n\\n# Remove punctuation and special characters\\ntext = &#39;&#39;.join(e for e in text if e.isalnum() or e.isspace())\\n\\n# Tokenize text (naive method)\\nwords = text.split()\\n\\n# Initialize spell checker\\nspell = SpellChecker()\\n\\n# Find misspelled words\\nmisspelled = spell.unknown(words)\\n\\n# Print result\\nprint(f\\&quot;Number of misspelled words: &#123;len(misspelled)&#125;\\&quot;)\\n\\nThis snippet will output a number of misspelled words found in the text.\\n\\nIn order to measure the efficiency in terms of false negatives and false positives, you need to know the true positives and true negatives, which requires the ground truth that in this case would be some kind of ‘clean’ version of the text without typos. \\n\\nWe can perform a counter-example with a small list that has good and bad spelled word:\\npython\\n# Assuming we have two lists which contain correctly spelled and incorrectly spelled words.\\ncorrectly_spelled = [&#39;apple&#39;, &#39;banana&#39;, &#39;pear&#39;]\\nincorrectly_spelled = [&#39;aple&#39;, &#39;banan&#39;, &#39;per&#39;]\\n\\n# Everything the spellchecker says is fine should be in the correctly spelled list.\\nfalse_negatives = [word for word in correctly_spelled + incorrectly_spelled if word not in spell.known([word])]\\n\\n# Everything the spellchecker says is wrong should be in the incorrectly spelled list.\\nfalse_positives = [word for word in correctly_spelled + incorrectly_spelled if word not in spell.unknown([word])]\\n\\nprint(f\\&quot;False Negatives: &#123;false_negatives&#125;\\&quot;)\\nprint(f\\&quot;False Positives: &#123;false_positives&#125;\\&quot;)\\n\\n\\nVisualizing results can be done in many ways depending on your preferences and exact needs. In simple cases, you could list the incorrectly spelled words found by the spell checker, but you could also create a plot using matplotlib, or a word cloud using the WordCloud module.\\n\\nTo improve the spell checker, you can add words to its dictionary. The pyspellchecker has a corpus we can add our words, as shown below:\\n\\npython\\nupdated_dictionary = set(list(spell.word_frequency.dictionary.keys()) + [\\&quot;additional\\&quot;, \\&quot;dictionary\\&quot;, \\&quot;words\\&quot;])\\nspell.word_frequency.load_words(updated_dictionary)\\n\\n\\nIf you have a custom dictionary, you can just load this directly.\\n\\nPyspellchecker probabilities are based on the occurrence of a word in the text. As a result, the more domain-specific text you can provide it, the more accurate it becomes.\\n\\nAnother optimization could be to apply a stemming algorithm before comparing words to the dictionary since the dictionary typically includes only root words.\\n\\nIn addition, you can use Machine Learning or Natural Language Processing techniques to improve spell check. Techniques such as:\\n1. Using a context-based spelling correction by using BERT model. \\n2. Training a customized spell-check model using a dataset relevant to your problem.\\n3. Using N-gram approach, where the context of the word is used for the correction (this is used in Google\\u2019s spell checker as of 2010).\\n4. Use of phonetic algorithms (e.g., Soundex, Metaphone, etc.) which are used to correct phonetically misspelled words.”} CodeExercise-Python-27k： 基于chatgpt生成的高质量python练习题数据 e.x.{“data_name”: “CodeExercise-Py”, “id”: 0, “chat_rounds”: [{“role”: “human”, “content”: “Write a Python function named &quot;add_numbers&quot; that takes two parameters, &quot;num1&quot; and &quot;num2&quot;, and returns the sum of the two numbers.\\nInput: None”, “chat_round_id”: 0}, {“role”: “bot”, “content”: “python\\ndef add_numbers(num1, num2):\\n \\&quot;\\&quot;\\&quot;\\n This function takes two numbers as input and returns their sum.\\n\\n Parameters:\\n num1 (int or float): The first number.\\n num2 (int or float): The second number.\\n\\n Returns:\\n int or float: The sum of num1 and num2.\\n \\&quot;\\&quot;\\&quot;\\n return num1 + num2\\n\\n# Example usage\\nresult = add_numbers(5, 3)\\nprint(result) # Output: 8\\n\\n\\n“, “chat_round_id”: 1}]} 闻达：一个大规模语言模型调用平台1. 知识库检索增强 sentence_transformers + 检索，支持faiss&#x2F;fess检索，可以选择本地&#x2F;在线检索、索引预先&#x2F;实时构建 没有提到长文本能力，仅仅是取决于model本身的功能 DeepBI1. 定义&#x2F;底模 基于OPENAI GPT4 模型开发的BI系统，可以自动生成sql与图表 核心问题是：如何在通过API的情况下优化SQL生成与结果分析？图表生成是模型生成还是调用某些库方法？ 初步判断是用了python的第三方包，如pyecharts等进行图表生成；完全调用GPT4 API，似乎仅在prompt上做了一些简单的处理？ 还是midware的思想；在代码生成上，没有做到交叉生成，python和sql生成是分开的 CodeT5+ 模型结构：encoder-decoder结构 编码器学习从代码&#x2F;文本序列（完整、部分或跨度屏蔽序列）中对上下文表示进行编码。 根据预训练学习任务，解码器被训练以生成不同类型的输出。 预训练任务的混合使模型能够学习代码上下文的有意义的表示，并在不同级别恢复丢失的信息：代码跨度、部分程序和完整程序。 训练策略：多任务混合 目的是增强LLM的理解能力 结合了不同类型的学习任务，包括span denoising, causal language modeling (CLM), text-code contrastive learning, and matching tasks（跨度去噪、因果语言建模（CLM）、文本代码对比学习和匹配任务）。他们发现，如此广泛的预训练任务集可以帮助模型从代码和文本数据中学习丰富的表示，并弥合各种应用中的预训练微调差距。 如何实现通过对模型进行调整加速训练？—————shallow encoder and deep decoder策略 keep the small encoder and the cross-attention layers trainable while freezing the deep decoder LLM. ————Such architecture is designed with the intuition that the decoder is often employed to deal with a higher level of complexity in generation tasks and requires a larger number of neural parameters. 训练trick unimodal code data and bimodal code-text data.（纯代码 + 代码与注释？） 二阶段预训练策略（实践证明可以增强更丰富的文本表示） 第一阶段只采用纯代码训练：从GitHub等开源平台获得了数据（许可证）。总共采用了九种编程语言的多语言培训数据。 第二阶段采用代码+文本作为训练数据：每个数据样本都包含一个文本代码对，其中包括一个代码函数及其相应的描述函数语义的文档字符串。 Instruction Tuning tuning the models with synthetic instruction-following tasks 下列为可能参考到的论文及启发点————LLM agent for generating code with python and SQL1. CleanAgent: Automating Data Standardization with LLM-based Agents 提出一个具有声明性、统一 API 的 Python 库，用于标准化列类型，通过简洁的 API 调用简化 LLM 的代码生成。 类似与midware的思想，加了一个中间层方便tuning，实际价值似乎不大 2. LiveCodeBench: Holistic and Contamination Free Evaluation of Large Language Models for Code 一套code generation效果评价方法，MIT伯克利大学出品，或许可以一试 3. KnowCoder: Coding Structured Knowledge into LLMs for Universal Information Extraction 中国科学院大学CAS Key Laboratory of Network Data Science and Technology出品 旨在开发一种LLM易于理解的统一模式表示，以及鼓励LLM遵循模式并准确提取结构化知识的有效学习框架（Universal Information Extraction (UIE) task） 已有UIE方法的一些不足：在类别及其归属的判定上、关联与实体的存在条件判断上不足；classification label&#x2F;自然语言 对LLM来说需要更多资源去理解；缺乏通用性 此文章实际上是用python代码来表示知识和信息，是information to python再to knowledge的过程","categories":[],"tags":[]},{"title":"云服务器使用及QQ机器人搭建","slug":"PcrQQbot","date":"2023-06-15T10:36:51.000Z","updated":"2023-06-15T11:12:36.159Z","comments":true,"path":"2023/06/15/PcrQQbot/","link":"","permalink":"https://yukino256.github.io/2023/06/15/PcrQQbot/","excerpt":"","text":"1. 服务器选择三个主流的：阿里云、腾讯云、华为云。萌新的我需要三选一华为云没用过。阿里云学生认证可以白嫖，腾讯云学生认证是打折，看着蛮便宜，但是这个时间买是1.9折，去年11月是1.1折。 服务器使用阿里云，因为可以白嫖7个月，新手上路还是找免费的试一下比较好，随便造，造坏了也不心疼。 cpu、内存这些东西就是看钱的啦，根据需要购买合适的就行。系统这个东西，不太清楚是怎么选择的。本人选择Ubuntu的依据是：尽管windows很熟悉，但是几个资深程序员的哥们儿用的都是Linux内核系统；此外，Liunx相对于windows的内存占用要小太多了，服务器还是要抠抠搜搜一点。Linux提供服务好像也蛮方便的 2. 服务器操作跟着阿里的教程走下来，基本上就会怎么操纵服务器了。远程连接服务器有两种方式：Workbench和VNC，前者似乎只能用命令行输入，后者则可以安装GUI。 实际上，不同云服务商对于自己云服务器的名称和操纵方式是有所不同的。 3. 图形界面的安装我的一个朋友对我说，只有当你能够用命令行完成你想要的所有操作后，你才算是真正懂计算机，我觉得很有道理。目前还没有这个能力，先用带GUI的VNC试一下，后续需要理解Workbench的命令行是什么东西，如何操作。其实目前在没有GUI的情况下无法理解系统内部结构。 GUI安装流程的方法，阿里云本身有提供，最终选择的系统是Ubuntun20.04。一开始选择的18.04的造了半天python安装还是出问题。因为机器人需求3.8的python，18.04默认是3.6，升级过程中会出现很多问题。 4. PCR会战机器人的选择之前主流是yobot，但是会战改版后用不了了，开发者不更新了。HoshinoBot是我一开始配置的，结果用不了会战功能，但是其他花里胡哨的似乎挺全。配置方法按照这个Liunx的安装流程走就是了。 实际上好像在哪里都无所谓？但是部署在这个位置的时候，运行.bat的时候，命令行显示的是： 顶级难蚌：18.04在numpy上安装疯狂失败，20.04一路绿灯😅 我这个服务器的带宽低，不用清华镜像的时候很慢。应该加上镜像设置的命令😇 1`python3.8 -m pip install -i https://pypi.tuna.tsinghua.edu.cn/simple -r requirements.txt` yobot_remix是yobot针对新版公会战的魔改，实测公会战能用。由于是基于yobot改的，命令和部署方法大体也和yobot相同 5. 机器人没响应典中典，被风控了，可以自行搜索解决方法。这个里面的高赞回答很有用 后记 阿里云给我白嫖7个月…应该尽快学习Docker的用法，方便后续迁移😋","categories":[{"name":"python","slug":"python","permalink":"https://yukino256.github.io/categories/python/"},{"name":"Liunx","slug":"python/Liunx","permalink":"https://yukino256.github.io/categories/python/Liunx/"},{"name":"Ubuntu20.04","slug":"python/Liunx/Ubuntu20-04","permalink":"https://yukino256.github.io/categories/python/Liunx/Ubuntu20-04/"}],"tags":[{"name":"QQbot","slug":"QQbot","permalink":"https://yukino256.github.io/tags/QQbot/"},{"name":"阿里云","slug":"阿里云","permalink":"https://yukino256.github.io/tags/%E9%98%BF%E9%87%8C%E4%BA%91/"},{"name":"cloud_server","slug":"cloud-server","permalink":"https://yukino256.github.io/tags/cloud-server/"}]},{"title":"AI绘画初步尝试：Stable Difussion本地部署及WebUI使用","slug":"AIdrawing","date":"2023-04-25T06:10:31.000Z","updated":"2023-04-25T07:30:37.718Z","comments":true,"path":"2023/04/25/AIdrawing/","link":"","permalink":"https://yukino256.github.io/2023/04/25/AIdrawing/","excerpt":"","text":"1. 安装conda、git、cudaCuda版本需要首先查看自己nvida显卡参数，不能高于参数上的版本 2. Conda创建环境，python版本根据GitHub上的说明来选择 1`conda create --name sdweb python=3.10.6` 3. 进入创建的虚拟环境1`conda activate sdweb` 4. 在虚拟环境下克隆项目，注意：命令行需要cd到虚拟环境的目录，不然会默认git到c盘….1`git clone https://github.com/AUTOMATIC1111/stable-diffusion-webui.git` 实际上好像在哪里都无所谓？但是部署在这个位置的时候，运行.bat的时候，命令行显示的是： 123`Creating venv in directory D:\\Anaconda3\\envs\\sdweb\\stable-diffusion-webui\\venv using python &quot;D:\\Anaconda3\\python.exe&quot;``venv &quot;D:\\Anaconda3\\envs\\sdweb\\stable-diffusion-webui\\venv\\Scripts\\Python.exe&quot;``Python 3.10.9 | packaged by Anaconda, Inc. | (main, Mar 1 2023, 18:18:15) [MSC v.1916 64 bit (AMD64)]` 没有用虚拟环境下的python版本哎….但是存储位置好歹是对了 😇 不对！或许应该在虚拟环境下用命令行运行这个.bat而不是点击！ 环境对了，但是运行时系统突然卡死一段时间……不敢动不敢动 😰错误显示是Torch安装失败，这个文章有提到把.bat的代码改一下，尝试之。 第六行改为： 1`set COMMANDLINE_ARGS=--lowvram --precision full --no-half --skip-torch-cuda-test` 这个.bat文件是另一个.bat的参数传入文件。 又寄啦，而且途中很卡 😅 5. 还是看看电子佛祖布施的法器吧嘉人们 😋 【AI绘画】Stable Diffusion整合包v4 BV1iM4y1y7oA","categories":[{"name":"python","slug":"python","permalink":"https://yukino256.github.io/categories/python/"},{"name":"algorithm","slug":"python/algorithm","permalink":"https://yukino256.github.io/categories/python/algorithm/"}],"tags":[{"name":"AI","slug":"AI","permalink":"https://yukino256.github.io/tags/AI/"},{"name":"Stable Difussion","slug":"Stable-Difussion","permalink":"https://yukino256.github.io/tags/Stable-Difussion/"},{"name":"本地部署","slug":"本地部署","permalink":"https://yukino256.github.io/tags/%E6%9C%AC%E5%9C%B0%E9%83%A8%E7%BD%B2/"}]},{"title":"记录自己的初次搭建博客的经历——流程、路径与感悟","slug":"BlogBuilding","date":"2023-04-24T07:30:58.000Z","updated":"2023-04-24T12:02:23.519Z","comments":true,"path":"2023/04/24/BlogBuilding/","link":"","permalink":"https://yukino256.github.io/2023/04/24/BlogBuilding/","excerpt":"","text":"安装流程可以参见 [这篇文章] (https://zhuanlan.zhihu.com/p/158975269)部署时尤其需要注意的设置：将hexo设置里面的分支名称改成与GitHub一致，因为前两年GitHub把main branch名字改了.. 1.网站部署的原理和逻辑是什么？在最开始，面对各种搭建网站的框架，本人其实是迷茫的，因为我一时间无法理解为什么经过这些步骤就能够产出一个可以被访问的页面？直到我在站点快搭建完成时，我才突然明白其原理，或许接下来的要说理解有点不准确，但是仍然在这里记录一下： 首先，需要理解的就是，网络上所有的资源都是以二进制的方式传输的，网站也是这样，传输的是010101的数据流，而不是直接将页面呈现在电脑上。数据在经过网络传输至本地的时候，需要本地利用某种“解码软件”将其转换成更高级的、便于用户阅读、输入的模式。浏览器其实就是将01数据解析成html等代码，然后再通过渲染、代码执行，将数据以GUI的形式呈现出来的解析器。 那么，为什么可以将页面文件夹的一整个数据包托管至某个服务器，从而能够对外可见呢？在GitHub中，如果你建立一个仓库，并将网站数据上传至仓库，利用GitHub Pages功能就可以将个人博客发布在互联网上。实际上，通过给仓库开通Pages功能，在输入 “用户名.github.io“ 时，你实际访问的是GitHub页面下你仓库的地址（这么说不知道对不对？），然后GitHub在你访问的时候，会检查仓库中是否有index.html这一个文件，如果有，则告诉浏览器，让浏览器解析仓库内的数据资源，从而使得页面能够呈现出来。 为什么是index.html？因为其是所有网站建设者约定俗成的一个最初始的入口文件，就好像python包中的__init__.py一样。 在理清上述逻辑之后，那么我们就可以理解到一个事实：站点部署在哪里都是无所谓的，只要站点托管的地方能够提供这样一种”判断” “解析”的服务即可，自己的电脑也可以作为server。只是PC经常保持不在线的状态，会影响用户访问。所以购买一个专门负责发送数据的服务器成为网站搭建的必要步骤，这种服务器专门处理访问网站的请求，效率上相对于PC高得多。 2.站点部署在哪？Github Pages，部署在这里的原因有两个：一是免费，二是顺带学习一下Github的用法 部署在这也有缺点，那就是国内访问不稳定 3.部署步骤？ git工具的安装、npm安装、Node.js安装（？）Node.js和npm分别是什么？————问问chatGPT吧！ 使用git将本地电脑与GitHub账户绑定 创建一个Github仓库，命名格式严格要求为：用户名.github.io 使用git命令行，将本地电脑的某个地址与github仓库关联，这个地址即是博客的文件所在，我命名为Blog 在Blog下，用git bash安装Hexo 使用Hexo命令，创建、测试、部署 4.主题个性化修改 选择一个主题并根据github上面提供的主题使用方法进行配置，此步骤git命令往往是在Blog这个根目录下进行 主题目录参见Hexo主题官方集合 经过一系列尝试，最终使用butterfly主题 个性化设置参见butterfly官方文档集，这是创作者的博客，博文全是详细的设置如何调整 5.博文上传与修改 需要注意的是，Hexo框架才是个人博客的架构，博客发表、修改等应该使用Hexo命令来执行 butterfly只是一个美化的框架，负责显示效果的渲染和调整 使用hexo命令创建新博文后，在source文件夹下可以找到。博文需要以md格式写作，本人使用VScode编写 md语法写作规范：Markdown官方教程 6.过程中踩过的坑仓库中README.md文件，在depoly后一直被顶替，仓库页面显示不出md的描述来这个问题是Hexo的设置问题，不知道官方文档有没有提到，但是解决方法是：在Hexo目录下的source根目录下添加一个README.md。修改Hexo目录下的_config.yml。将skip_render参数的值设置上。skip_render: README.md保存退出即可。使用hexo d 命令就不会在渲染 README.md 这个文件了。 无法在仓库中手动添加README.md,因为部署时候会将仓库内容完全顶替为本地内容，只有在本地文件中也设置README才行。 网站在本地测试渲染失败可能是缺少相应的包，重新安装一遍即可，如果不确定，就从头都试一下通常而言，应该安装的包有：Hexo所需的包+所用主题渲染所需的包 引出一个问题：包的作用是什么？ 主题包：hexo-theme-fluid 是加入主题 渲染包：hexo-renderer-scss 是加入渲染引擎，因为Hexo里面可能并不支持主题内的一些样式 又引出一个问题：为什么不支持？Hexo究竟是什么？本人尚未了解，但是可以参见Hexo官方文档 网站本地测试成功，部署到GitHub后远程渲染失败？按F12，查看console，发现报错是Failed to load resource: the server responded with a status of 404 ()原因在于国内与GitHub的连接犯抽……..一些文件没下载回来因而无法加载 因为这个错误换了好多主题….本来其他主题也蛮漂亮的唉… 但是新页面还有问题，可能在我不知道的地方起了作用，尽管显示没有问题：Error with Permissions-Policy header: Origin trial controlled feature not enabled: ‘interest-cohort’. 其实在途中还遇到一个错误，稀里糊涂就没有了。 7.后续考虑加入的功能[博客定时自动更新] (https://hexo.io/zh-cn/docs/one-command-deployment.html)很简单，没搞是因为没必要，学习是需要时间的，不需要频繁更新……. 动态页面真正理解Hexo的底层原理8.一些感想 在配置过程中遇到过很多报错、和不了解的地方，直接搜索报错结果固然可以找到解决方法，但是很多可以查阅官方文档来解决。查阅固然快，但往往会使得”知其然而不知其所以然”。直接搜答案的过程和询问chatGPT很类似，工程性的问题只答复解决步骤，而不分析背后原理 Hexo也许是一套程序，自动提供一套框架，功能是将我们提交的文本，按照模板或者自己设定的样子渲染出来。同样功能的还要jekell，但是好像是Linux上比较好用。Hexo是静态网页框架，对于博客够用，但是动态网页框架才是未来的选择。 在编写md的时候还误用了中文符号导致md语法出错…….wssb 部署后发现页面没更新？刷新试试！再不然就开梯子刷新试试！ 原来写正文的时候不用自动换行….否则会突然换行，很难看.. Markdown语法：加粗这类修饰语法，前后如果有标点符号，则要视情况加空格…… 每次更新，clean、g、d三条命令必须走一趟啊….我还以为用更新用g、d就行了呢 bolg内插入图片失败…解决方法是这篇博客","categories":[{"name":"markdown","slug":"markdown","permalink":"https://yukino256.github.io/categories/markdown/"},{"name":"js","slug":"markdown/js","permalink":"https://yukino256.github.io/categories/markdown/js/"},{"name":"css","slug":"markdown/js/css","permalink":"https://yukino256.github.io/categories/markdown/js/css/"}],"tags":[{"name":"Hexo","slug":"Hexo","permalink":"https://yukino256.github.io/tags/Hexo/"},{"name":"Blog","slug":"Blog","permalink":"https://yukino256.github.io/tags/Blog/"},{"name":"Git","slug":"Git","permalink":"https://yukino256.github.io/tags/Git/"},{"name":"Github","slug":"Github","permalink":"https://yukino256.github.io/tags/Github/"}]},{"title":"YukinoのBlog","slug":"bolgname","date":"2023-04-20T03:33:24.000Z","updated":"2023-04-24T07:24:32.896Z","comments":true,"path":"2023/04/20/bolgname/","link":"","permalink":"https://yukino256.github.io/2023/04/20/bolgname/","excerpt":"","text":"这是搭建自己第一个博客后的第一篇文章","categories":[],"tags":[]},{"title":"Hello World","slug":"hello-world","date":"2023-04-20T03:30:32.320Z","updated":"2023-04-20T03:30:32.320Z","comments":true,"path":"2023/04/20/hello-world/","link":"","permalink":"https://yukino256.github.io/2023/04/20/hello-world/","excerpt":"","text":"Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub. Quick StartCreate a new post1$ hexo new &quot;My New Post&quot; More info: Writing Run server1$ hexo server More info: Server Generate static files1$ hexo generate More info: Generating Deploy to remote sites1$ hexo deploy More info: Deployment","categories":[],"tags":[]}],"categories":[{"name":"python","slug":"python","permalink":"https://yukino256.github.io/categories/python/"},{"name":"Liunx","slug":"python/Liunx","permalink":"https://yukino256.github.io/categories/python/Liunx/"},{"name":"Ubuntu20.04","slug":"python/Liunx/Ubuntu20-04","permalink":"https://yukino256.github.io/categories/python/Liunx/Ubuntu20-04/"},{"name":"algorithm","slug":"python/algorithm","permalink":"https://yukino256.github.io/categories/python/algorithm/"},{"name":"markdown","slug":"markdown","permalink":"https://yukino256.github.io/categories/markdown/"},{"name":"js","slug":"markdown/js","permalink":"https://yukino256.github.io/categories/markdown/js/"},{"name":"css","slug":"markdown/js/css","permalink":"https://yukino256.github.io/categories/markdown/js/css/"}],"tags":[{"name":"QQbot","slug":"QQbot","permalink":"https://yukino256.github.io/tags/QQbot/"},{"name":"阿里云","slug":"阿里云","permalink":"https://yukino256.github.io/tags/%E9%98%BF%E9%87%8C%E4%BA%91/"},{"name":"cloud_server","slug":"cloud-server","permalink":"https://yukino256.github.io/tags/cloud-server/"},{"name":"AI","slug":"AI","permalink":"https://yukino256.github.io/tags/AI/"},{"name":"Stable Difussion","slug":"Stable-Difussion","permalink":"https://yukino256.github.io/tags/Stable-Difussion/"},{"name":"本地部署","slug":"本地部署","permalink":"https://yukino256.github.io/tags/%E6%9C%AC%E5%9C%B0%E9%83%A8%E7%BD%B2/"},{"name":"Hexo","slug":"Hexo","permalink":"https://yukino256.github.io/tags/Hexo/"},{"name":"Blog","slug":"Blog","permalink":"https://yukino256.github.io/tags/Blog/"},{"name":"Git","slug":"Git","permalink":"https://yukino256.github.io/tags/Git/"},{"name":"Github","slug":"Github","permalink":"https://yukino256.github.io/tags/Github/"}]}