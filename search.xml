<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title>AI绘画初步尝试：Stable Difussion本地部署及WebUI使用</title>
    <url>/2023/04/25/AIdrawing/</url>
    <content><![CDATA[<h2 id="1-安装conda、git、cuda"><a href="#1-安装conda、git、cuda" class="headerlink" title="1.	安装conda、git、cuda"></a>1.	安装conda、git、cuda</h2><p>Cuda版本需要首先查看自己nvida显卡参数，不能高于参数上的版本</p>
<h2 id="2-Conda创建环境，"><a href="#2-Conda创建环境，" class="headerlink" title="2.	Conda创建环境，"></a>2.	Conda创建环境，</h2><p>python版本根据<a href="https://github.com/AUTOMATIC1111/stable-diffusion-webui">GitHub上的说明</a>来选择</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">`conda create --name sdweb python=3.10.6`</span><br></pre></td></tr></table></figure>

<h2 id="3-进入创建的虚拟环境"><a href="#3-进入创建的虚拟环境" class="headerlink" title="3.	进入创建的虚拟环境"></a>3.	进入创建的虚拟环境</h2><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">`conda activate sdweb`</span><br></pre></td></tr></table></figure>

<h2 id="4-在虚拟环境下克隆项目，注意：命令行需要cd到虚拟环境的目录，不然会默认git到c盘…"><a href="#4-在虚拟环境下克隆项目，注意：命令行需要cd到虚拟环境的目录，不然会默认git到c盘…" class="headerlink" title="4.	在虚拟环境下克隆项目，注意：命令行需要cd到虚拟环境的目录，不然会默认git到c盘…."></a>4.	在虚拟环境下克隆项目，注意：命令行需要cd到虚拟环境的目录，不然会默认git到c盘….</h2><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">`git clone https://github.com/AUTOMATIC1111/stable-diffusion-webui.git`</span><br></pre></td></tr></table></figure>

<p>实际上好像在哪里都无所谓？但是部署在这个位置的时候，运行.bat的时候，命令行显示的是：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">`Creating venv in directory D:\Anaconda3\envs\sdweb\stable-diffusion-webui\venv using python &quot;D:\Anaconda3\python.exe&quot;`</span><br><span class="line">`venv &quot;D:\Anaconda3\envs\sdweb\stable-diffusion-webui\venv\Scripts\Python.exe&quot;`</span><br><span class="line">`Python 3.10.9 | packaged by Anaconda, Inc. | (main, Mar  1 2023, 18:18:15) [MSC v.1916 64 bit (AMD64)]`</span><br></pre></td></tr></table></figure>

<p>没有用虚拟环境下的python版本哎….但是存储位置好歹是对了 😇</p>
<p>不对！或许应该在虚拟环境下用命令行运行这个.bat而不是点击！</p>
<p>环境对了，但是运行时系统突然卡死一段时间……不敢动不敢动 😰<br>错误显示是Torch安装失败<img src="error1.png" alt="error" title="错误报告">，这个文章有提到把.bat的代码改一下，尝试之。</p>
<p>第六行改为：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">`set COMMANDLINE_ARGS=--lowvram --precision full --no-half --skip-torch-cuda-test`</span><br></pre></td></tr></table></figure>

<p>这个.bat文件是另一个.bat的参数传入文件。</p>
<p>又寄啦，而且途中很卡 😅</p>
<hr>
<h2 id="5-还是看看电子佛祖布施的法器吧嘉人们-😋"><a href="#5-还是看看电子佛祖布施的法器吧嘉人们-😋" class="headerlink" title="5.	还是看看电子佛祖布施的法器吧嘉人们 😋"></a>5.	还是看看电子佛祖布施的法器吧嘉人们 😋</h2><p> <strong>【AI绘画】Stable Diffusion整合包v4  <a href="https://www.bilibili.com/video/BV1iM4y1y7oA">BV1iM4y1y7oA</a></strong></p>
]]></content>
      <categories>
        <category>python</category>
        <category>algorithm</category>
      </categories>
      <tags>
        <tag>AI</tag>
        <tag>Stable Difussion</tag>
        <tag>本地部署</tag>
      </tags>
  </entry>
  <entry>
    <title>Hello World</title>
    <url>/2023/04/20/hello-world/</url>
    <content><![CDATA[<p>Welcome to <a href="https://hexo.io/">Hexo</a>! This is your very first post. Check <a href="https://hexo.io/docs/">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href="https://hexo.io/docs/troubleshooting.html">troubleshooting</a> or you can ask me on <a href="https://github.com/hexojs/hexo/issues">GitHub</a>.</p>
<h2 id="Quick-Start"><a href="#Quick-Start" class="headerlink" title="Quick Start"></a>Quick Start</h2><h3 id="Create-a-new-post"><a href="#Create-a-new-post" class="headerlink" title="Create a new post"></a>Create a new post</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ hexo new <span class="string">&quot;My New Post&quot;</span></span><br></pre></td></tr></table></figure>

<p>More info: <a href="https://hexo.io/docs/writing.html">Writing</a></p>
<h3 id="Run-server"><a href="#Run-server" class="headerlink" title="Run server"></a>Run server</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ hexo server</span><br></pre></td></tr></table></figure>

<p>More info: <a href="https://hexo.io/docs/server.html">Server</a></p>
<h3 id="Generate-static-files"><a href="#Generate-static-files" class="headerlink" title="Generate static files"></a>Generate static files</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ hexo generate</span><br></pre></td></tr></table></figure>

<p>More info: <a href="https://hexo.io/docs/generating.html">Generating</a></p>
<h3 id="Deploy-to-remote-sites"><a href="#Deploy-to-remote-sites" class="headerlink" title="Deploy to remote sites"></a>Deploy to remote sites</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ hexo deploy</span><br></pre></td></tr></table></figure>

<p>More info: <a href="https://hexo.io/docs/one-command-deployment.html">Deployment</a></p>
]]></content>
  </entry>
  <entry>
    <title>记录自己的初次搭建博客的经历——流程、路径与感悟</title>
    <url>/2023/04/24/BlogBuilding/</url>
    <content><![CDATA[<p>安装流程可以参见 [这篇文章] (<a href="https://zhuanlan.zhihu.com/p/158975269">https://zhuanlan.zhihu.com/p/158975269</a>)<br>部署时尤其需要注意的设置：将hexo设置里面的分支名称改成与GitHub<a href="https://zhuanlan.zhihu.com/p/345841098">一致</a>，因为前两年GitHub把main branch名字改了..</p>
<h2 id="1-网站部署的原理和逻辑是什么？"><a href="#1-网站部署的原理和逻辑是什么？" class="headerlink" title="1.网站部署的原理和逻辑是什么？"></a>1.网站部署的原理和逻辑是什么？</h2><p>在最开始，面对各种搭建网站的框架，本人其实是迷茫的，因为我一时间无法理解为什么经过这些步骤就能够产出一个可以被访问的页面？<br>直到我在站点快搭建完成时，我才突然明白其原理，或许接下来的要说理解有点不准确，但是仍然在这里记录一下：  </p>
<ol>
<li>首先，需要理解的就是，网络上所有的资源都是以二进制的方式传输的，网站也是这样，传输的是010101的数据流，而不是直接将页面呈现在电脑上。数据在经过网络传输至本地的时候，需要本地利用某种“解码软件”将其转换成更高级的、便于用户阅读、输入的模式。浏览器其实就是将01数据解析成html等代码，然后再通过渲染、代码执行，将数据以GUI的形式呈现出来的解析器。</li>
<li>那么，为什么可以将页面文件夹的一整个数据包托管至某个服务器，从而能够对外可见呢？在GitHub中，如果你建立一个仓库，并将网站数据上传至仓库，利用GitHub Pages功能就可以将个人博客发布在互联网上。实际上，通过给仓库开通Pages功能，在输入 <strong>“用户名.github.io</strong>“ 时，你实际访问的是GitHub页面下你仓库的地址（这么说不知道对不对？），然后GitHub在你访问的时候，会检查仓库中是否有index.html这一个文件，如果有，则告诉浏览器，让浏览器解析仓库内的数据资源，从而使得页面能够呈现出来。</li>
<li>为什么是index.html？因为其是所有网站建设者约定俗成的一个最初始的入口文件，就好像python包中的__init__.py一样。</li>
<li>在理清上述逻辑之后，那么我们就可以理解到一个事实：站点部署在哪里都是无所谓的，只要站点托管的地方能够提供这样一种”判断”  “解析”的服务即可，自己的电脑也可以作为server。只是PC经常保持不在线的状态，会影响用户访问。所以购买一个专门负责发送数据的服务器成为网站搭建的必要步骤，这种服务器专门处理访问网站的请求，效率上相对于PC高得多。</li>
</ol>
<h2 id="2-站点部署在哪？"><a href="#2-站点部署在哪？" class="headerlink" title="2.站点部署在哪？"></a>2.站点部署在哪？</h2><p>Github Pages，部署在这里的原因有两个：一是免费，二是顺带学习一下Github的用法</p>
<p>部署在这也有缺点，那就是国内访问不稳定</p>
<h2 id="3-部署步骤？"><a href="#3-部署步骤？" class="headerlink" title="3.部署步骤？"></a>3.部署步骤？</h2><ul>
<li>git工具的安装、npm安装、Node.js安装（？）<br>Node.js和npm分别是什么？————问问chatGPT吧！</li>
<li>使用git将本地电脑与GitHub账户绑定</li>
<li>创建一个Github仓库，命名格式严格要求为：用户名.github.io</li>
<li>使用git命令行，将本地电脑的某个地址与github仓库关联，这个地址即是博客的文件所在，我命名为Blog</li>
<li>在Blog下，用git bash安装Hexo</li>
<li>使用Hexo命令，创建、测试、部署</li>
</ul>
<h2 id="4-主题个性化修改"><a href="#4-主题个性化修改" class="headerlink" title="4.主题个性化修改"></a>4.主题个性化修改</h2><ul>
<li>选择一个主题并根据github上面提供的主题使用方法进行配置，此步骤git命令往往是在Blog这个根目录下进行</li>
<li>主题目录参见<a href="https://hexo.io/themes/">Hexo主题官方集合</a></li>
<li>经过一系列尝试，最终使用butterfly主题</li>
<li>个性化设置参见<a href="https://butterfly.js.org/">butterfly官方文档集</a>，这是创作者的博客，博文全是详细的设置如何调整</li>
</ul>
<h2 id="5-博文上传与修改"><a href="#5-博文上传与修改" class="headerlink" title="5.博文上传与修改"></a>5.博文上传与修改</h2><ul>
<li>需要注意的是，Hexo框架才是个人博客的架构，博客发表、修改等应该使用Hexo命令来执行</li>
<li>butterfly只是一个美化的框架，负责显示效果的渲染和调整</li>
<li>使用hexo命令创建新博文后，在source文件夹下可以找到。博文需要以md格式写作，本人使用VScode编写</li>
<li>md语法写作规范：<a href="https://markdown.com.cn/basic-syntax/">Markdown官方教程</a></li>
</ul>
<h2 id="6-过程中踩过的坑"><a href="#6-过程中踩过的坑" class="headerlink" title="6.过程中踩过的坑"></a>6.过程中踩过的坑</h2><h3 id="仓库中README-md文件，在depoly后一直被顶替，仓库页面显示不出md的描述来"><a href="#仓库中README-md文件，在depoly后一直被顶替，仓库页面显示不出md的描述来" class="headerlink" title="仓库中README.md文件，在depoly后一直被顶替，仓库页面显示不出md的描述来"></a>仓库中README.md文件，在depoly后一直被顶替，仓库页面显示不出md的描述来</h3><p>这个问题是Hexo的设置问题，不知道官方文档有没有提到，但是解决方法是：在Hexo目录下的source根目录下添加一个README.md。修改Hexo目录下的_config.yml。将skip_render参数的值设置上。skip_render: README.md保存退出即可。使用hexo d 命令就不会在渲染 README.md 这个文件了。  </p>
<p>无法在仓库中手动添加README.md,因为部署时候会将仓库内容完全顶替为本地内容，只有在本地文件中也设置README才行。</p>
<h3 id="网站在本地测试渲染失败"><a href="#网站在本地测试渲染失败" class="headerlink" title="网站在本地测试渲染失败"></a>网站在本地测试渲染失败</h3><p>可能是缺少相应的包，重新安装一遍即可，如果不确定，就从头都试一下<br>通常而言，应该安装的包有：Hexo所需的包+所用主题渲染所需的包  </p>
<p>引出一个问题：包的作用是什么？</p>
<ol>
<li>主题包：hexo-theme-fluid 是加入主题</li>
<li>渲染包：hexo-renderer-scss 是加入渲染引擎，因为Hexo里面可能并不支持主题内的一些样式</li>
</ol>
<p>又引出一个问题：为什么不支持？Hexo究竟是什么？<br>本人尚未了解，但是可以参见<a href="https://hexo.io/zh-cn/">Hexo官方文档</a></p>
<h3 id="网站本地测试成功，部署到GitHub后远程渲染失败？"><a href="#网站本地测试成功，部署到GitHub后远程渲染失败？" class="headerlink" title="网站本地测试成功，部署到GitHub后远程渲染失败？"></a>网站本地测试成功，部署到GitHub后远程渲染失败？</h3><p>按F12，查看console，发现报错是Failed to load resource: the server responded with a status of 404 ()<br>原因在于国内与GitHub的连接犯抽……..一些文件没下载回来因而无法加载</p>
<p>因为这个错误换了好多主题….本来其他主题也蛮漂亮的唉… </p>
<p>但是新页面还有问题，可能在我不知道的地方起了作用，尽管显示没有问题：<br>Error with Permissions-Policy header: Origin trial controlled feature not enabled: ‘interest-cohort’.</p>
<p>其实在途中还遇到一个错误，稀里糊涂就没有了。</p>
<h2 id="7-后续考虑加入的功能"><a href="#7-后续考虑加入的功能" class="headerlink" title="7.后续考虑加入的功能"></a>7.后续考虑加入的功能</h2><h3 id="博客定时自动更新-https-hexo-io-zh-cn-docs-one-command-deployment-html"><a href="#博客定时自动更新-https-hexo-io-zh-cn-docs-one-command-deployment-html" class="headerlink" title="[博客定时自动更新] (https://hexo.io/zh-cn/docs/one-command-deployment.html)"></a>[博客定时自动更新] (<a href="https://hexo.io/zh-cn/docs/one-command-deployment.html">https://hexo.io/zh-cn/docs/one-command-deployment.html</a>)</h3><p>很简单，没搞是因为没必要，学习是需要时间的，不需要频繁更新…….<br><img src="Heroku.png" alt="Heroku" title="配置示例"></p>
<h3 id="动态页面"><a href="#动态页面" class="headerlink" title="动态页面"></a>动态页面</h3><h3 id="真正理解Hexo的底层原理"><a href="#真正理解Hexo的底层原理" class="headerlink" title="真正理解Hexo的底层原理"></a>真正理解Hexo的底层原理</h3><h2 id="8-一些感想"><a href="#8-一些感想" class="headerlink" title="8.一些感想"></a>8.一些感想</h2><ul>
<li>在配置过程中遇到过很多报错、和不了解的地方，直接搜索报错结果固然可以找到解决方法，但是很多可以查阅官方文档来解决。查阅固然快，但往往会使得”知其然而不知其所以然”。直接搜答案的过程和询问chatGPT很类似，工程性的问题只答复解决步骤，而不分析背后原理</li>
<li>Hexo也许是一套程序，自动提供一套框架，功能是将我们提交的文本，按照模板或者自己设定的样子渲染出来。同样功能的还要jekell，但是好像是Linux上比较好用。Hexo是静态网页框架，对于博客够用，但是动态网页框架才是未来的选择。</li>
<li>在编写md的时候还误用了中文符号导致md语法出错…….wssb</li>
<li>部署后发现页面没更新？刷新试试！再不然就开梯子刷新试试！</li>
<li>原来写正文的时候不用自动换行….否则会突然换行，很难看..</li>
<li>Markdown语法：加粗这类修饰语法，前后如果有标点符号，则要视情况加空格……</li>
<li>每次更新，clean、g、d三条命令必须走一趟啊….我还以为用更新用g、d就行了呢</li>
<li>bolg内插入图片失败…解决方法是<a href="https://zhuanlan.zhihu.com/p/542101567">这篇博客</a></li>
</ul>
]]></content>
      <categories>
        <category>markdown</category>
        <category>js</category>
        <category>css</category>
      </categories>
      <tags>
        <tag>Hexo</tag>
        <tag>Blog</tag>
        <tag>Git</tag>
        <tag>Github</tag>
      </tags>
  </entry>
  <entry>
    <title>YukinoのBlog</title>
    <url>/2023/04/20/bolgname/</url>
    <content><![CDATA[<h1 id="这是搭建自己第一个博客后的第一篇文章"><a href="#这是搭建自己第一个博客后的第一篇文章" class="headerlink" title="这是搭建自己第一个博客后的第一篇文章"></a>这是搭建自己第一个博客后的第一篇文章</h1>]]></content>
  </entry>
  <entry>
    <title>云服务器使用及QQ机器人搭建</title>
    <url>/2023/06/15/PcrQQbot/</url>
    <content><![CDATA[<h2 id="1-服务器选择"><a href="#1-服务器选择" class="headerlink" title="1.	服务器选择"></a>1.	服务器选择</h2><p>三个主流的：阿里云、腾讯云、华为云。萌新的我需要三选一<br>华为云没用过。阿里云学生认证可以白嫖，腾讯云学生认证是打折，看着蛮便宜，但是这个时间买是1.9折，去年11月是1.1折。</p>
<p>服务器使用阿里云，因为可以白嫖7个月，新手上路还是找免费的试一下比较好，随便造，造坏了也不心疼。</p>
<p>cpu、内存这些东西就是看钱的啦，根据需要购买合适的就行。<br>系统这个东西，不太清楚是怎么选择的。本人选择Ubuntu的依据是：尽管windows很熟悉，但是几个资深程序员的哥们儿用的都是Linux内核系统；此外，Liunx相对于windows的内存占用要小太多了，服务器还是要抠抠搜搜一点。<br>Linux提供服务好像也蛮方便的</p>
<h2 id="2-服务器操作"><a href="#2-服务器操作" class="headerlink" title="2.	服务器操作"></a>2.	服务器操作</h2><p>跟着阿里的教程走下来，基本上就会怎么操纵服务器了。远程连接服务器有两种方式：Workbench和VNC，前者似乎只能用命令行输入，后者则可以安装GUI。</p>
<p>实际上，不同云服务商对于自己云服务器的名称和操纵方式是有所不同的。</p>
<h2 id="3-图形界面的安装"><a href="#3-图形界面的安装" class="headerlink" title="3.	图形界面的安装"></a>3.	图形界面的安装</h2><p>我的一个朋友对我说，只有当你能够用命令行完成你想要的所有操作后，你才算是真正懂计算机，我觉得很有道理。目前还没有这个能力，先用带GUI的VNC试一下，后续需要理解Workbench的命令行是什么东西，如何操作。其实目前在没有GUI的情况下无法理解系统内部结构。</p>
<p>GUI安装流程的方法，阿里云本身有<a href="https://help.aliyun.com/document_detail/59330.html">提供</a>，最终选择的系统是Ubuntun20.04。<br>一开始选择的18.04的造了半天python安装还是出问题。因为机器人需求3.8的python，18.04默认是3.6，升级过程中会出现很多问题。</p>
<h2 id="4-PCR会战机器人的选择"><a href="#4-PCR会战机器人的选择" class="headerlink" title="4.	PCR会战机器人的选择"></a>4.	PCR会战机器人的选择</h2><p>之前主流是yobot，但是会战改版后用不了了，开发者不更新了。<br><a href="https://github.com/Ice9Coffee/HoshinoBot">HoshinoBot</a>是我一开始配置的，结果用不了会战功能，但是其他花里胡哨的似乎挺全。配置方法按照这个Liunx的安装流程走就是了。</p>
<p>实际上好像在哪里都无所谓？但是部署在这个位置的时候，运行.bat的时候，命令行显示的是：</p>
<p>顶级难蚌：18.04在numpy上安装疯狂失败，20.04一路绿灯😅<br><img src="success.png" alt="success" title="成功"></p>
<p>我这个服务器的带宽低，不用清华镜像的时候很慢。应该加上镜像设置的命令😇</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">`python3.8 -m pip install -i https://pypi.tuna.tsinghua.edu.cn/simple -r requirements.txt`</span><br></pre></td></tr></table></figure>


<p><a href="https://github.com/eggggi/yobot_remix">yobot_remix</a>是yobot针对新版公会战的魔改，实测公会战能用。由于是基于yobot改的，<a href="https://yobot.pcrbot.com/features/">命令和部署方法</a>大体也和yobot相同</p>
<h2 id="5-机器人没响应"><a href="#5-机器人没响应" class="headerlink" title="5.	机器人没响应"></a>5.	机器人没响应</h2><p>典中典，被风控了，可以自行搜索解决方法。<br><a href="https://github.com/Mrs4s/go-cqhttp/issues/958">这个</a>里面的高赞回答很有用</p>
<hr>
<h2 id="后记阿里云给我白嫖7个月…应该尽快学习Docker的用法，方便后续迁移😋"><a href="#后记阿里云给我白嫖7个月…应该尽快学习Docker的用法，方便后续迁移😋" class="headerlink" title="后记	阿里云给我白嫖7个月…应该尽快学习Docker的用法，方便后续迁移😋"></a>后记	阿里云给我白嫖7个月…应该尽快学习Docker的用法，方便后续迁移😋</h2>]]></content>
      <categories>
        <category>python</category>
        <category>Liunx</category>
        <category>Ubuntu20.04</category>
      </categories>
      <tags>
        <tag>QQbot</tag>
        <tag>阿里云</tag>
        <tag>cloud_server</tag>
      </tags>
  </entry>
  <entry>
    <title>第一次实习前的一些准备工作与知识储备</title>
    <url>/2024/03/14/%E5%AE%9E%E4%B9%A0%E5%87%86%E5%A4%87/</url>
    <content><![CDATA[<h1 id="千帆杯原生应用挑战赛"><a href="#千帆杯原生应用挑战赛" class="headerlink" title="千帆杯原生应用挑战赛"></a>千帆杯原生应用挑战赛</h1><ol>
<li><strong>大赛主旨</strong>：大赛以“创意无限·生成未来”为主题，紧密围绕当前AI技术的前沿动态和应用趋势，借助百度智能云千帆AppBuilder和ModelBuilder两大智能开发助手，鼓励参赛者打造出更多具有创新性、实用性和社会价值的AI原生应用  <ul>
<li><strong>第一期</strong>：游乐场排队规划助手：赛题聚焦春节假期游乐园排队效率问题，鼓励开发者利用 AI 能力施展“时间魔法”，打造一款具有实用性的“游乐场排队规划助手”，帮助游客更好地了解乐园的排队情况，设计个性化的游玩路线，在有限的时间内获得最“High”的体验，同时为管理者提供优化运营策略的决策支持。  <blockquote>
<ul>
<li>此大赛没有规定数据集，需求成果是使用主办方框架的应用程序。参赛者需要自己获取相关数据，如大赛第一名使用的是香港迪士尼数据</li>
</ul>
</blockquote>
</li>
<li><strong>第二期</strong>：生成一个可制作贺岁文案内容的精调模型（限定使用ERNIE Speed，通过对模型精调使其保持原有能力的同时，具备准确理解并执行文案创作中创作长度相关指令的能力）。<blockquote>
<ul>
<li>此大赛提供了少量数据集（56）条，同时要求对数据集进行扩展（最终至少需要100条数据），数据为json形式</li>
<li>与第一期不同，此期是方向特化的微调模型开发，需要使用主办方框架</li>
</ul>
</blockquote>
</li>
</ul>
</li>
<li><strong>大赛形式</strong>：<ul>
<li><strong>第一期</strong>：基于AppBuilder平台提供的强大开发套件和资源环境，使用平台预置的Agent框架，以零代码的方式创建Agent智能体，自动化调用各种工具打造游乐场排队规划助手AI原生应用。<blockquote>
<ul>
<li>游客只需要输入时间预算和游玩喜好，Agent智能体就能生成并执行Python代码，求解优化问题，智能规划出游玩项目路线。<br>————————生成python，求解optimization问题的agent</li>
</ul>
</blockquote>
</li>
<li><strong>第二期</strong>：通过在千帆大模型平台使用平台上的各种模型调优工具，结合相关数据，基于ERNIE-Speed调优生成符合赛题主题要求且效果优秀的模型。  <blockquote>
<ul>
<li><strong>作品信息需包含</strong>：  <blockquote>
<ul>
<li>微调后的模型效果展示（输入输出示例截图）  </li>
<li>部署后的模型API文档（包含url地址、超参配置和步骤描述）  </li>
<li>access_token；<br></li>
</ul>
</blockquote>
</li>
</ul>
</blockquote>
</li>
</ul>
</li>
</ol>
<h1 id="阿里天池竞赛"><a href="#阿里天池竞赛" class="headerlink" title="阿里天池竞赛"></a>阿里天池竞赛</h1><h2 id="1-基于LLM智能问答系统学习赛"><a href="#1-基于LLM智能问答系统学习赛" class="headerlink" title="1. 基于LLM智能问答系统学习赛"></a><strong>1. 基于LLM智能问答系统学习赛</strong></h2><blockquote>
<ul>
<li><strong>赛题思想：未来金融科技领域将深刻体现Agent的价值，即一个智能代理能根据用户需求进行意图识别和决策。本次大赛的赛题虽为单一，但融合了数据查询与文本理解两大任务，充分体现了Agent核心思想：根据不确定输入，判断用户意图，并调用相应服务或功能生成答案。</strong></li>
</ul>
</blockquote>
<blockquote>
<ul>
<li><strong>模型使用：不限制选手的模型使用，选手可以选择商业化模型或者开源模型，也可以结合多个模型，共同创建一个问答系统。可以采用Prompt Engineering方法，也可以使用外部数据对模型进行微调。推荐使用“通义千问金融大模型”或“通义千问7B模型”作为基础大模型，</strong></li>
</ul>
</blockquote>
<blockquote>
<ul>
<li><strong>任务目标：数据查询题——根据用户的问题，生成相应的SQL查询语句，精准查询问题结果；文本理解题：对长文本进行细致检索与解读，高效提取关键信息。</strong></li>
</ul>
</blockquote>
<blockquote>
<ul>
<li><strong><a href="https://www.modelscope.cn/datasets/BJQW14B/bs_challenge_financial_14b_dataset/summary">数据集描述</a>：赛事主办方提供三类数据。一个是10张数据表（sqlite），一个是招股说明书（pdf文件，标准的招股说明书形式，没有进行数据处理），以及将招股说明书pdf解析后的txt文件。</strong></li>
</ul>
</blockquote>
<blockquote>
<ul>
<li><strong>大模型拓展操作：扩展金融行业词表；增量训练行业金融200B规模，涵盖中英文财报、研报、新闻、书籍、论坛等多种类型数据；</strong><br><strong><font color="#FF0000">训练上下文扩展到16K，借助NTK和LogN等技术，推理长度可以扩展到64K</font></strong></li>
</ul>
</blockquote>
<h2 id="2-通义千问AI挑战赛-Code-Qwen能力算法赛道"><a href="#2-通义千问AI挑战赛-Code-Qwen能力算法赛道" class="headerlink" title="2. 通义千问AI挑战赛 - Code Qwen能力算法赛道"></a><strong>2. 通义千问AI挑战赛 - Code Qwen能力算法赛道</strong></h2><blockquote>
<ul>
<li><strong>目的：如何通过高质量的数据微调提升基础语言模型的代码能力？——聚焦于通义千问大模型微调训练的竞赛，其主要目标是通过高质量的数据探索和拓展开源模型 Qwen 1.8B 及 Qwen 72B 的代码能力上限。高质量的数据是大模型提升效果的关键，初赛阶段主要聚焦在如何通过 SFT 提升基础模型的代码能力。需要选手基于最新开源的 Qwen 1.8 模型作为基础模型，在提供的训练框架上自行进行数据收集与微调，训练完成后将进行自动评估，返回最终结果进行排名；</strong></li>
<li><strong>数据集特征</strong><blockquote>
<ul>
<li><strong><a href="https://huggingface.co/datasets/codefuse-ai/Evol-instruction-66k">Evol-instruction-66k</a>：	基于开源open-evol-instruction-80k过滤低质量，重复和human eval相似的数据后得到的高质量代码类微调数据</strong><blockquote>
<ul>
<li><strong>e.x.</strong>{<br>  <strong>“instruction”</strong>: “Using the text file from the link, <a href="https://norvig.com/big.txt">https://norvig.com/big.txt</a>, use the SpellChecker module from the pyspellchecker package in Python to find spelling mistakes in the text file. Additionally, measure the efficiency of the implemented spell checker. Report the number of false positives and false negatives, and provide a way to visualize these instances. Also, improve the spell checker by using custom dictionaries or other natural language processing techniques to reduce these errors.”,<br>  <strong>“output”</strong>: “Here is an outline of how to address this problem:\n(Note we will need to install <code>pyspellchecker</code> and <code>requests</code> dependencies if not present already). You can install it using:\n<code>\npip install pyspellchecker requests\n</code>\n\n<code>python\nimport requests\nfrom spellchecker import SpellChecker\n\n# Get the text file\nurl = \&quot;https://norvig.com/big.txt\&quot;\nresponse = requests.get(url)\ntext = response.text\n\n# Remove punctuation and special characters\ntext = &#39;&#39;.join(e for e in text if e.isalnum() or e.isspace())\n\n# Tokenize text (naive method)\nwords = text.split()\n\n# Initialize spell checker\nspell = SpellChecker()\n\n# Find misspelled words\nmisspelled = spell.unknown(words)\n\n# Print result\nprint(f\&quot;Number of misspelled words: &#123;len(misspelled)&#125;\&quot;)\n</code>\nThis snippet will output a number of misspelled words found in the text.\n\nIn order to measure the efficiency in terms of false negatives and false positives, you need to know the true positives and true negatives, which requires the ground truth that in this case would be some kind of ‘clean’ version of the text without typos. \n\nWe can perform a counter-example with a small list that has good and bad spelled word:\n<code>python\n# Assuming we have two lists which contain correctly spelled and incorrectly spelled words.\ncorrectly_spelled = [&#39;apple&#39;, &#39;banana&#39;, &#39;pear&#39;]\nincorrectly_spelled = [&#39;aple&#39;, &#39;banan&#39;, &#39;per&#39;]\n\n# Everything the spellchecker says is fine should be in the correctly spelled list.\nfalse_negatives = [word for word in correctly_spelled + incorrectly_spelled if word not in spell.known([word])]\n\n# Everything the spellchecker says is wrong should be in the incorrectly spelled list.\nfalse_positives = [word for word in correctly_spelled + incorrectly_spelled if word not in spell.unknown([word])]\n\nprint(f\&quot;False Negatives: &#123;false_negatives&#125;\&quot;)\nprint(f\&quot;False Positives: &#123;false_positives&#125;\&quot;)\n</code>\n\nVisualizing results can be done in many ways depending on your preferences and exact needs. In simple cases, you could list the incorrectly spelled words found by the spell checker, but you could also create a plot using matplotlib, or a word cloud using the WordCloud module.\n\nTo improve the spell checker, you can add words to its dictionary. The pyspellchecker has a corpus we can add our words, as shown below:\n\n<code>python\nupdated_dictionary = set(list(spell.word_frequency.dictionary.keys()) + [\&quot;additional\&quot;, \&quot;dictionary\&quot;, \&quot;words\&quot;])\nspell.word_frequency.load_words(updated_dictionary)\n</code>\n\nIf you have a custom dictionary, you can just load this directly.\n\nPyspellchecker probabilities are based on the occurrence of a word in the text. As a result, the more domain-specific text you can provide it, the more accurate it becomes.\n\nAnother optimization could be to apply a stemming algorithm before comparing words to the dictionary since the dictionary typically includes only root words.\n\nIn addition, you can use Machine Learning or Natural Language Processing techniques to improve spell check. Techniques such as:\n1. Using a context-based spelling correction by using BERT model. \n2. Training a customized spell-check model using a dataset relevant to your problem.\n3. Using N-gram approach, where the context of the word is used for the correction (this is used in Google\u2019s spell checker as of 2010).\n4. Use of phonetic algorithms (e.g., Soundex, Metaphone, etc.) which are used to correct phonetically misspelled words.”<br>}</li>
</ul>
</blockquote>
</li>
</ul>
</blockquote>
</li>
</ul>
</blockquote>
<blockquote>
<blockquote>
<ul>
<li><strong><a href="https://huggingface.co/datasets/codefuse-ai/CodeExercise-Python-27k">CodeExercise-Python-27k</a>：	基于chatgpt生成的高质量python练习题数据</strong><blockquote>
<ul>
<li><strong>e.x.</strong>{<strong>“data_name”</strong>: “CodeExercise-Py”, <strong>“id”</strong>: 0, <strong>“chat_rounds”</strong>: [{<strong>“role”</strong>: “human”, <strong>“content”</strong>: “Write a Python function named &quot;add_numbers&quot; that takes two parameters, &quot;num1&quot; and &quot;num2&quot;, and returns the sum of the two numbers.\nInput: None”, “chat_round_id”: 0}, {<strong>“role”</strong>: “bot”, <strong>“content”</strong>: “<code>python\ndef add_numbers(num1, num2):\n    \&quot;\&quot;\&quot;\n    This function takes two numbers as input and returns their sum.\n\n    Parameters:\n    num1 (int or float): The first number.\n    num2 (int or float): The second number.\n\n    Returns:\n    int or float: The sum of num1 and num2.\n    \&quot;\&quot;\&quot;\n    return num1 + num2\n\n# Example usage\nresult = add_numbers(5, 3)\nprint(result)  # Output: 8\n\n\n</code>“, “chat_round_id”: 1}]}</li>
</ul>
</blockquote>
</li>
</ul>
</blockquote>
</blockquote>
<br>

<h1 id="闻达：一个大规模语言模型调用平台"><a href="#闻达：一个大规模语言模型调用平台" class="headerlink" title="闻达：一个大规模语言模型调用平台"></a><a href="https://github.com/wenda-LLM/wenda">闻达：一个大规模语言模型调用平台</a></h1><h2 id="1-知识库检索增强"><a href="#1-知识库检索增强" class="headerlink" title="1. 知识库检索增强"></a><strong>1.</strong> <strong>知识库检索增强</strong></h2><blockquote>
<ul>
<li><strong>sentence_transformers + 检索，支持faiss&#x2F;fess检索，可以选择本地&#x2F;在线检索、索引预先&#x2F;实时构建</strong></li>
<li><strong>没有提到长文本能力，仅仅是取决于model本身的功能</strong></li>
</ul>
</blockquote>
<h1 id="DeepBI"><a href="#DeepBI" class="headerlink" title="DeepBI"></a><a href="https://github.com/DeepInsight-AI/DeepBI/tree/main">DeepBI</a></h1><h2 id="1-定义-x2F-底模"><a href="#1-定义-x2F-底模" class="headerlink" title="1. 定义&#x2F;底模"></a><strong>1.</strong> <strong>定义&#x2F;底模</strong></h2><blockquote>
<ul>
<li><strong>基于OPENAI GPT4 模型开发的BI系统，可以自动生成sql与图表</strong></li>
<li><strong>核心问题是：如何在通过API的情况下优化SQL生成与结果分析？图表生成是模型生成还是调用某些库方法？</strong><blockquote>
<ul>
<li><strong>初步判断是用了python的第三方包，如pyecharts等进行图表生成；完全调用GPT4 API，似乎仅在prompt上做了一些简单的处理？</strong></li>
<li><strong>还是midware的思想；在代码生成上，没有做到交叉生成，python和sql生成是分开的</strong></li>
</ul>
</blockquote>
</li>
</ul>
</blockquote>
<h1 id="CodeT5"><a href="#CodeT5" class="headerlink" title="CodeT5+"></a>CodeT5+</h1><ol>
<li><h2 id="模型结构：encoder-decoder结构"><a href="#模型结构：encoder-decoder结构" class="headerlink" title="模型结构：encoder-decoder结构"></a><strong>模型结构：encoder-decoder结构</strong></h2><ul>
<li><strong>编码器学习从代码&#x2F;文本序列（完整、部分或跨度屏蔽序列）中对上下文表示进行编码。</strong></li>
<li><strong>根据预训练学习任务，解码器被训练以生成不同类型的输出。</strong></li>
<li><strong>预训练任务的混合使模型能够学习代码上下文的有意义的表示，并在不同级别恢复丢失的信息：代码跨度、部分程序和完整程序。</strong></li>
</ul>
</li>
<li><h2 id="训练策略：多任务混合"><a href="#训练策略：多任务混合" class="headerlink" title="训练策略：多任务混合"></a><strong>训练策略：多任务混合</strong></h2><ul>
<li><strong>目的是增强LLM的理解能力</strong></li>
<li><strong>结合了不同类型的学习任务，包括span denoising, causal language modeling (CLM), text-code contrastive learning, and matching tasks（跨度去噪、因果语言建模（CLM）、文本代码对比学习和匹配任务）。他们发现，如此广泛的预训练任务集可以帮助模型从代码和文本数据中学习丰富的表示，并弥合各种应用中的预训练微调差距。</strong></li>
<li><strong>如何实现通过对模型进行调整加速训练？—————shallow encoder and deep decoder策略</strong>  <blockquote>
<ul>
<li><strong>keep the small encoder and the cross-attention layers trainable while freezing the deep decoder LLM. ————Such architecture is designed with the intuition that the decoder is often employed to deal with a higher level of complexity in generation tasks and requires a larger number of neural parameters.</strong></li>
</ul>
</blockquote>
</li>
</ul>
</li>
<li><h2 id="训练trick"><a href="#训练trick" class="headerlink" title="训练trick"></a><strong>训练trick</strong></h2><ul>
<li><strong>unimodal code data and bimodal code-text data.（纯代码 + 代码与注释？）</strong></li>
<li><strong>二阶段预训练策略（实践证明可以增强更丰富的文本表示）</strong><blockquote>
<ul>
<li><strong>第一阶段只采用纯代码训练：从GitHub等开源平台获得了数据（许可证）。总共采用了九种编程语言的多语言培训数据。</strong></li>
<li><strong>第二阶段采用代码+文本作为训练数据：每个数据样本都包含一个文本代码对，其中包括一个代码函数及其相应的描述函数语义的文档字符串。</strong></li>
</ul>
</blockquote>
</li>
<li><strong>Instruction Tuning</strong><blockquote>
<ul>
<li><strong>tuning the models with synthetic instruction-following tasks</strong></li>
</ul>
</blockquote>
</li>
</ul>
</li>
</ol>
 <br>
  <br>

<h1 id="下列为可能参考到的论文及启发点"><a href="#下列为可能参考到的论文及启发点" class="headerlink" title="下列为可能参考到的论文及启发点"></a>下列为可能参考到的论文及启发点</h1><h1 id="————LLM-agent-for-generating-code-with-python-and-SQL"><a href="#————LLM-agent-for-generating-code-with-python-and-SQL" class="headerlink" title="————LLM agent for generating code with python and SQL"></a>————LLM agent for generating code with python and SQL</h1><h2 id="1-CleanAgent-Automating-Data-Standardization-with-LLM-based-Agents"><a href="#1-CleanAgent-Automating-Data-Standardization-with-LLM-based-Agents" class="headerlink" title="1. CleanAgent: Automating Data Standardization with LLM-based Agents"></a>1. CleanAgent: Automating Data Standardization with LLM-based Agents</h2><blockquote>
<ul>
<li><strong>提出一个具有声明性、统一 API 的 Python 库，用于标准化列类型，通过简洁的 API 调用简化 LLM 的代码生成。</strong></li>
<li><strong>类似与midware的思想，加了一个中间层方便tuning，实际价值似乎不大</strong></li>
</ul>
</blockquote>
<h2 id="2-LiveCodeBench-Holistic-and-Contamination-Free-Evaluation-of-Large-Language-Models-for-Code"><a href="#2-LiveCodeBench-Holistic-and-Contamination-Free-Evaluation-of-Large-Language-Models-for-Code" class="headerlink" title="2. LiveCodeBench: Holistic and Contamination Free Evaluation of Large Language Models for Code"></a>2. LiveCodeBench: Holistic and Contamination Free Evaluation of Large Language Models for Code</h2><blockquote>
<ul>
<li><strong>一套code generation效果评价方法，MIT伯克利大学出品，或许可以一试</strong></li>
</ul>
</blockquote>
<h2 id="3-KnowCoder-Coding-Structured-Knowledge-into-LLMs-for-Universal-Information-Extraction"><a href="#3-KnowCoder-Coding-Structured-Knowledge-into-LLMs-for-Universal-Information-Extraction" class="headerlink" title="3. KnowCoder: Coding Structured Knowledge into LLMs for Universal Information Extraction"></a>3. KnowCoder: Coding Structured Knowledge into LLMs for Universal Information Extraction</h2><blockquote>
<ul>
<li><strong>中国科学院大学CAS Key Laboratory of Network Data Science and Technology出品</strong></li>
<li><strong>旨在开发一种LLM易于理解的统一模式表示，以及鼓励LLM遵循模式并准确提取结构化知识的有效学习框架（Universal Information Extraction (UIE) task）</strong></li>
<li><strong>已有UIE方法的一些不足：在类别及其归属的判定上、关联与实体的存在条件判断上不足；classification label&#x2F;自然语言 对LLM来说需要更多资源去理解；缺乏通用性</strong></li>
<li><strong>此文章实际上是用python代码来表示知识和信息，是information to python再to knowledge的过程</strong></li>
</ul>
</blockquote>
]]></content>
  </entry>
  <entry>
    <title>DailyRecord-March</title>
    <url>/2024/03/20/DailyRecord-March/</url>
    <content><![CDATA[<h1 id="3-20"><a href="#3-20" class="headerlink" title="3.20"></a>3.20</h1><p><strong>入职的第一天，接到的任务是：把闻达的demo在服务器上用docker给搭建出来。于是我在服务器上先创建了一个miniconda3的docker，然后使用conda安装了一些依赖、git项目等；其间遇到一个问题：docker+conda后，尽管bash上显示是root，但是好像是一个虚拟的root，没有sudo等的执行文件，需要重新安装一下。此外，公司的网有点差，清华源1Mb、不用清华源只有几十kb。因而进展较慢</strong><br><strong>部署步骤进行到了模型下载这一步，但是因为网不好所以连不上hugging face，需要搭梯子。下班了，明天再搞！</strong>  </p>
<blockquote>
<ul>
<li><strong>明日任务：搞定梯子，下载好生成模型和embedding模型，最终完成demo，并调整远程访问展示</strong></li>
</ul>
</blockquote>
<h1 id="3-21"><a href="#3-21" class="headerlink" title="3.21"></a>3.21</h1><p><strong>今天签合同了。</strong><br><strong>搭梯子问题卡了好久😡。这国企是一天也不能待了，网差的要死。最后还是前辈哥帮忙解决的。</strong><br><strong>但是terminal的命令，下载的那些怎么都那么几把慢啊！网速是压力之源！</strong><br><strong>更悲剧的是：今日闻达demo部署至最后一步无法运行…………..</strong><br><strong>可能是docker的问题，因而将其删除从头开始搭建。如果明天仍然不行，则尝试不用docker直接在服务器上部署</strong>  </p>
<h2 id="他妈的！狗日的北京通勤太痛苦了！"><a href="#他妈的！狗日的北京通勤太痛苦了！" class="headerlink" title=" 他妈的！狗日的北京通勤太痛苦了！ "></a><font color="red"> <strong>他妈的！狗日的北京通勤太痛苦了！</strong> </font></h2><blockquote>
<ul>
<li><strong>明日任务：wenda的demo。哎我真佛了这个b服务器 + docker好难用，不能直接在服务器安装conda吗，conda创建虚拟环境不也挺方便的</strong></li>
</ul>
</blockquote>
<h1 id="3-22"><a href="#3-22" class="headerlink" title="3.22"></a>3.22</h1><p><strong>创建了一个git的container，但是在安装lfs的时候出了问题，需要用sudo等一些命令，但是apt下载很慢，似乎需要在docker file文件中就更换镜像源</strong><br><strong>了解了docker中与宿主机相互cp文件、docker在创建时需要用GPU对容器可见的命令；</strong></p>
<blockquote>
<ul>
<li>docker run -it –net&#x3D;host –gpus all –name 容器名 -e NVIDIA_DRIVER_CAPABILITIES&#x3D;compute,utility -e NVIDIA_VISIBLE_DEVICES&#x3D;all 镜像名</li>
</ul>
</blockquote>
<p><strong>闻达demo终于无报错安装起来了</strong><br><strong>但是运行的时候，模型似乎卡住&#x2F;死循环？不返回计算结果。</strong>  </p>
<h2 id="他妈的！压力一天比一天大！EMO了要！"><a href="#他妈的！压力一天比一天大！EMO了要！" class="headerlink" title=" 他妈的！压力一天比一天大！EMO了要！ "></a><font color="red"> <strong>他妈的！压力一天比一天大！EMO了要！</strong> </font></h2><h2 id="今天美好的事情："><a href="#今天美好的事情：" class="headerlink" title="今天美好的事情："></a><strong>今天美好的事情：</strong></h2><p><strong>与SL、ZYR一起在附近那啥招待所吃川菜。味道不错，就是环境有点热、菜有点辣。此外，和ZYR一起自行车骑行，他一路讲解，聊的很开心！到北京以来为数不多的快乐时间。</strong><br><strong>SL骑着他那破电瓶车，本来跟我们一起的，半路给交警罚款了，就让他回去了，唉，我好难过</strong></p>
<blockquote>
<ul>
<li><strong>下周任务：调整闻达demo</strong></li>
</ul>
</blockquote>
<h1 id="3-23-3-24-周末！"><a href="#3-23-3-24-周末！" class="headerlink" title="3.23-3.24  周末！"></a>3.23-3.24  周末！</h1><p><strong>早上乘坐地铁到清河，和NJ汇合，一起去清河</strong><br><strong>做了半小时火车到怀来辣！比北京通勤还快。下了火车有一种终于逃离压力之源的舒畅感。</strong><br><strong>中文在饭店吃了什么洋葱和羊肉炒的东西，味道不错；然后还吃了莜面、炒扁豆角；喝了营养快线味的酸奶、杏仁露。杏仁露味道不错，加热和不加热是两个味道</strong><br><strong>吃完饭和NJ一起顺路去菜市场买了点粑粑柑（最后一口没吃带回北京了）。然后不行一阵子去了宾馆，双人间一晚90，条件还挺不错….要哭了</strong><br><strong>睡了午觉，然后出去找网吧打了几把大乱斗；下了新赛季的第一把云顶，玩不明白好痛苦，老六老七出局。然后出去转了转，看了一下县城的风土人情，买了西安特产甑糕，味道也不错。天气不好，阴沉天空使我不太开心。</strong><br><strong>相对于老家，这里明显更荒凉一些，没有人、没有年轻人。</strong><br><strong>晚上吃了砂锅。酸菜白肉和竹笋炖腊肉的砂锅；点了傀儡（土豆和面的混合物作为主食？），咸咸的，有葱花。点了冰糖芦荟，和椰果罐头一个味儿。吃完又转了转。回到宾馆玩了把金铲铲，然后下去买了10斤的半个西瓜和勺子。吃了一点，大头给NJ吃了（真能吃啊这B）</strong><br><strong>睡了一晚，第二天早上吃了豆面还是什么东西，然后走路去买了个吊炉烧饼分着尝尝；NJ点了驴肉和驴肠火烧的外卖，带回北京吃了</strong><br><strong>和NJ回北京了，BYD带我在海淀区骑了好久的自行车，最后在一家新疆馆子吃了抓饭和羊肉什么馍，喝了北京的汽水（和芬达一个味），吃的挺好。就是这b人带我转来转去最后吃这种快餐属实没绷住</strong></p>
<h1 id="3-25"><a href="#3-25" class="headerlink" title="3.25"></a>3.25</h1><p><strong>闻达demo部署完毕辣！</strong><br><strong>接下来需要：尝试更换通义7B&#x2F;14B的模型；查看闻达前端技术栈，与前端做交接让其修改；部署另一个&#x2F;几个项目（似乎要加班，tmd！）</strong><br><strong>已经将底模更新为7B，但是14B可能需要双卡，还不了解他这个框架怎么放到双卡上；</strong><br><strong>前端框架不太清楚，但是有一个二次开发的前端框架正在尝试，但是服务器网不好，nodejs安装困难。</strong><br><strong>下午看了B站上的一个从零开始大模型，感觉有点收获。还有一部分没看完</strong> </p>
<blockquote>
<ul>
<li><strong>明日任务：或许需要看一下另一个agent代理的部署；看langchain和LLM的相关教程视频；RAG目前似乎有一套实践模板，基于faiss检索？</strong></li>
</ul>
</blockquote>
<h1 id="3-26"><a href="#3-26" class="headerlink" title="3.26"></a>3.26</h1><p><strong>早上看langchain的视频教程</strong><br><strong>下午部署了wenda的二次开发webui，其中有报错；能保证基本的对话，但是文档对话功能用不了</strong><br><strong>下午抽空去免了腾讯的NLP应用研究实习生，他们是做腾讯视频剧本理解与智能助手的，感觉挺有意思。花了114定了钟点房，可惜面试的时候网不好、代码题也没敲出来，BERT的损失函数、交叉熵也没回答好。</strong>  </p>
<ul>
<li><p><strong>和SH交流了一下面试的经历，他目前的实习产品经理似乎工资低但是很轻松。他说TX面试结果很快会出，就可以再投了，但是我到第二天也没看到结果</strong><br><strong>部署了langchain-chatchat，可以基本运行，但存在一些问题，如知识库检索似乎没有工作、模型更换没有前端，需要在后端尝试修改</strong>  </p>
</li>
<li><p><strong>回家，地铁上和ZJX吐槽工作的事情，交流中得到片刻的安慰；到家后，和NJ电话聊了聊，大诉苦水，得到了一些开导和建议，好兄弟！；夜里躺在床上，和LF聊了聊他的离职和走全奖去美国读PHD躺平5年。唏嘘之余，有点羡慕</strong>  </p>
</li>
<li><p><strong>似乎，上班的人状况都不是很好：ZYR精神衰弱吃药、LF压力大怼领导辞职、SX天天emo不想动，我自己的精神状态也不是很好，唉。唉！</strong></p>
<blockquote>
<ul>
<li><strong>明日任务：调整部署项目，学习</strong></li>
</ul>
</blockquote>
</li>
</ul>
<h1 id="3-27"><a href="#3-27" class="headerlink" title="3.27"></a>3.27</h1><p><strong>早上给领导演示了一下两个demo，边上的前辈哥部署的DB-GPT也看了；这个效果挺好，但是也有要调整的地方。如服务器上部署模型的API调用等</strong><br><strong>今天看阿里Qwen的vllm教程视频，大有收获</strong><br><strong>铸币吧，LLM聊天一个字一个字显示的效果原来是清屏+ 打印啊！前端或许就是&lt;div&gt;内部的反复刷新？</strong>  </p>
<blockquote>
<ul>
<li><strong>明日任务：调整部署项目，学习</strong></li>
</ul>
</blockquote>
<p>晚上，和妈妈聊了聊天，倾诉了一下。得知妹妹的奶奶肿瘤晚期，突然有一种恐惧和悲伤笼罩心头。帮妈妈网上填写了检查需要的材料，相关材料也进行了保存。与SH、LMD一起打了大乱斗，片刻的开心，但是过程中没有完全放松。</p>
<h1 id="3-28"><a href="#3-28" class="headerlink" title="3.28"></a>3.28</h1><p><strong>继续学习qwen+vllm的宝藏up主。对asyncio的内容有些不理解。这个up主好像是c++、java高手，学习大模型相关内容上手也很快，我感到很挫败。</strong>  </p>
<hr>
<hr>
<blockquote>
<ul>
<li><hr>
</li>
</ul>
</blockquote>
<p>悲苦萦绕心头，不能散去。可能真的是房子住的还是有点远，每天通勤1.5小时。或许我需要换租了。</p>
]]></content>
  </entry>
</search>
